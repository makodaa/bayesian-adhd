{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0250446",
   "metadata": {},
   "source": [
    "#### **EEG ADHD Classification: CNN-LSTM with Bayesian Optimization**\n",
    "\n",
    "This notebook implements a hybrid CNN-LSTM deep learning model for ADHD classification using EEG data. The model combines convolutional neural networks for spatial feature extraction with LSTM networks for temporal pattern recognition. Hyperparameter optimization is performed using Tree-structured Parzen Estimator (TPE) algorithm via Hyperopt, with an iterative convergence-based approach to ensure robust hyperparameter selection.\n",
    "\n",
    "#### **Key Features**\n",
    "- **Dual-stream architecture**: Combines raw EEG spatial-temporal features with engineered frequency band powers\n",
    "- **Iterative Bayesian Optimization**: Runs multiple BO searches until standard deviation of results converges\n",
    "- **Reproducible experiments**: Seed management for consistent results across runs\n",
    "- **Comprehensive evaluation**: Multiple cross-validation strategies including Leave-One-Subject-Out\n",
    "- **Early stopping**: Prevents overfitting with configurable patience parameter\n",
    "\n",
    "#### **Table of Contents**\n",
    "\n",
    "1. [First Imports](#first-imports) - Essential libraries for data processing, ML, and deep learning\n",
    "2. [Read the Processed Dataset](#read-the-processed-dataset) - Load preprocessed EEG data with frequency features\n",
    "3. [Group the Data](#group-the-data) - Reshape tabular data into 3D tensors for CNN-LSTM\n",
    "4. [Dataset Loading](#dataset-loading) - Custom PyTorch Dataset with dual-stream architecture\n",
    "5. [Model Creation](#model-creation) - Hybrid CNN-LSTM model with fusion and classification heads\n",
    "6. [First Model Training](#first-model-training) - Baseline model training with default hyperparameters\n",
    "7. [Helper Functions](#helper-functions) - Utilities for model creation, evaluation, and data loading\n",
    "8. [Search Space Definition](#search-space-definition) - Hyperparameter search space for Bayesian Optimization\n",
    "9. [Search Objective Definition](#search-objective-definition) - Objective function with train/test split or k-fold CV\n",
    "10. [Hyperparameter Search](#hyperparameter-search) - TPE search with configurable iterations and seeding\n",
    "11. [Results Visualization](#results-visualization) - Iterative BO with convergence tracking and analysis\n",
    "    - Convergence-based optimization with stability criteria\n",
    "    - Summary visualization of all BO runs\n",
    "    - Best parameter extraction and final model training\n",
    "12. [Cross-Validation Experiments](#cross-validation-experiments) - Window-based k-fold and LOSOCV evaluation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9fc3d7-ba3e-48bb-88a9-8ee38f5f1ab9",
   "metadata": {},
   "source": [
    "#### **First Imports**\n",
    "\n",
    "Import essential libraries for data manipulation, machine learning, and deep learning:\n",
    "- **NumPy/Pandas**: Data processing and manipulation\n",
    "- **Scikit-learn**: Train/test splitting, metrics, and label encoding\n",
    "- **PyTorch**: Deep learning framework for building and training neural networks\n",
    "- **Torch Optimizers**: Adam, RMSprop, and SGD for model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "181da2fc-dae6-4638-8d23-8214b7560c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, RMSprop, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2168c3-c347-46fa-b7d7-9f352e31fdd3",
   "metadata": {},
   "source": [
    "#### **Read the Processed Dataset**\n",
    "\n",
    "Load the preprocessed and clustered ADHD EEG dataset. This dataset contains:\n",
    "- **Frequency domain features**: Power spectral density values across different frequency bands\n",
    "- **Window segments**: Temporal windows extracted from continuous EEG recordings\n",
    "- **Electrode channels**: Data from 19 EEG electrodes plus 7 band power features\n",
    "- **Subject IDs**: For cross-validation and subject-independent testing\n",
    "- **Class labels**: ADHD diagnostic categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af714077-585f-4de6-b357-1e50dc4993ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./processed_clustered_adhdata.csv\")\n",
    "\n",
    "frequency_count = len(df['Frequency'].unique())\n",
    "window_count = len(df['Window'].unique())\n",
    "numeric_df = df.drop(['ID', 'Window'], axis=1)\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39df14e-ecc4-4a5d-80c9-66305657bc36",
   "metadata": {},
   "source": [
    "#### **Group the Data**\n",
    "\n",
    "Transform the 2D tabular data into 3D tensors suitable for CNN-LSTM processing:\n",
    "\n",
    "**Reshaping Process:**\n",
    "1. Group rows by window number to reconstruct temporal segments\n",
    "2. Create shape: `(WINDOW_COUNT, FREQUENCY_PER_WINDOW, ELECTRODES)`\n",
    "3. Separate features (X) from labels (y)\n",
    "4. Add channel dimension for CNN compatibility: `(N, freq, electrodes, 1)`\n",
    "\n",
    "**Train/Test Split:**\n",
    "- 80% training, 20% testing\n",
    "- Stratified sampling to maintain class distribution\n",
    "- Ensures balanced representation of all diagnostic categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe8775d-db75-48e4-a074-6190d80c2ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: (windows, frequencies, electrodes)\n",
    "full_ndarray = numeric_df.values.reshape((window_count, frequency_count, numeric_df.shape[1]))\n",
    "\n",
    "X = full_ndarray[:, :, 2:]     # drop ID/Class columns\n",
    "y = full_ndarray[:, 0, 0]      # class label is repeated across freq rows\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Add channel dimension (N, 1, freq, electrodes)\n",
    "X_train = X_train[..., np.newaxis]   # (N, freq, electrodes, 1)\n",
    "X_test  = X_test[...,  np.newaxis]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(\"Train shape:\", X_train.shape)  # (N, freq, electrodes, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed81cb7-3951-4889-a095-e59b7e0ea1a4",
   "metadata": {},
   "source": [
    "#### **Dataset Loading**\n",
    "\n",
    "Custom PyTorch Dataset class for EEG data with dual-stream architecture:\n",
    "\n",
    "**Features:**\n",
    "- **EEG Raw Features**: Spatial-temporal patterns from 19 electrodes (1, 77, 19)\n",
    "- **Band Power Features**: Pre-computed frequency band powers (7 features)\n",
    "- **Data Augmentation Ready**: Supports future augmentation strategies\n",
    "- **Batch Processing**: Efficient DataLoader integration\n",
    "\n",
    "**Architecture Rationale:**\n",
    "The dual-stream approach allows the model to learn both:\n",
    "1. Fine-grained spatial-temporal patterns via CNN-LSTM\n",
    "2. Engineered frequency domain features via dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2595397-63c0-4fd7-9f9a-4242370f5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "        # -> (N, 1, freq, electrodes)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]          # (1, 77, 26)\n",
    "\n",
    "        x_eeg  = x[:, :, :19]    # (1, 77, 19)\n",
    "        x_band = x[0, 0, 19:]    # (7,)\n",
    "\n",
    "        return x_eeg, x_band, self.y[idx]\n",
    "\n",
    "train_ds = EEGDataset(X_train, y_train)\n",
    "test_ds  = EEGDataset(X_test,  y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1002d8ce-9fbc-49a2-bc2b-cd3f38ed0d1b",
   "metadata": {},
   "source": [
    "#### **Model Creation**\n",
    "\n",
    "Hybrid CNN-LSTM architecture with dual-stream feature fusion:\n",
    "\n",
    "**CNN Branch (Spatial Feature Extraction):**\n",
    "- Conv2D layers with configurable kernels and sizes\n",
    "- Average pooling for downsampling\n",
    "- Dropout for regularization\n",
    "- Dense layer before LSTM for dimensionality reduction\n",
    "\n",
    "**LSTM Branch (Temporal Pattern Recognition):**\n",
    "- Multi-layer LSTM for sequence modeling\n",
    "- Configurable hidden size and layer depth\n",
    "- Dropout between LSTM layers\n",
    "- Final timestep aggregation\n",
    "\n",
    "**Band Power Branch:**\n",
    "- Dense layers for frequency domain features\n",
    "- ReLU activation and dropout\n",
    "\n",
    "**Fusion & Classification:**\n",
    "- Concatenate CNN-LSTM output with band power features\n",
    "- Two-layer classification head\n",
    "- Supports multi-class ADHD categorization\n",
    "\n",
    "**Training Features:**\n",
    "- Early stopping with patience parameter\n",
    "- Best model checkpoint restoration\n",
    "- Training/validation history tracking\n",
    "- Overfitting detection capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e658ff5-0dd2-4898-9f4a-d71d0cc79bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class EEGCNNLSTM(nn.Module):\n",
    "    def __init__(self, num_band_features=7, num_classes=4,\n",
    "                 cnn_kernels_1=32,\n",
    "                 cnn_kernel_size_1=3,\n",
    "                 cnn_kernels_2=32,\n",
    "                 cnn_kernel_size_2=3,\n",
    "                 cnn_dropout=0.3,\n",
    "                 cnn_dense=16,\n",
    "                 lstm_hidden_size=32,\n",
    "                 lstm_layers=4,\n",
    "                 lstm_dense=64,\n",
    "                 dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        pad1 = cnn_kernel_size_1 // 2\n",
    "        self.conv1   = nn.Conv2d(1, int(cnn_kernels_1), kernel_size=cnn_kernel_size_1, padding=pad1)\n",
    "        self.pool1 = nn.AvgPool2d(2)\n",
    "        \n",
    "        pad2 = cnn_kernel_size_2 // 2\n",
    "        self.conv2 = nn.Conv2d(int(cnn_kernels_1), int(cnn_kernels_2), kernel_size=cnn_kernel_size_2, padding=pad2)\n",
    "        self.cnn_dropout = nn.Dropout(cnn_dropout)\n",
    "\n",
    "        # Compute flatten size dynamically\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 1, X_train.shape[1], 19)\n",
    "            out = self._forward_cnn(dummy)   # [B, C, H, W]\n",
    "            b, c, h, w = out.shape\n",
    "            self.seq_len = h                      # sequence length (rows)\n",
    "            self.cnn_feat_dim = c * w             # CNN features per timestep\n",
    "\n",
    "        # Dense layer BEFORE LSTM\n",
    "        self.cnn_dense = nn.Linear(self.cnn_feat_dim, int(cnn_dense))\n",
    "\n",
    "        # Two stacked LSTM layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=int(cnn_dense),\n",
    "            hidden_size=int(lstm_hidden_size),\n",
    "            num_layers=int(lstm_layers),\n",
    "            batch_first=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0.0\n",
    "        )\n",
    "        # self.lstm_dense = nn.Linear(int(lstm_hidden_size), int(lstm_dense))\n",
    "        self.band_fc = nn.Sequential(\n",
    "            nn.Linear(num_band_features, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        \n",
    "        # final classifier (match your original final style: dropout + linear)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(int(lstm_hidden_size) + 32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes),\n",
    "        )\n",
    "\n",
    "    def _forward_cnn(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.cnn_dropout(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x_eeg, x_band):\n",
    "        # 1️⃣ CNN feature extraction\n",
    "        x = self._forward_cnn(x_eeg)             # [B, C, H, W]\n",
    "\n",
    "        # 2️⃣ Prepare sequence for LSTM\n",
    "        x = x.permute(0, 2, 1, 3)                 # [B, H, C, W]\n",
    "        x = x.contiguous().view(x.size(0), x.size(1), -1)  # [B, H, C*W]\n",
    "\n",
    "        # 3️⃣ Dense layer for each timestep\n",
    "        x = F.relu(self.cnn_dense(x))     # [B, H, dense_size]\n",
    "\n",
    "        # 4️⃣ Two-layer LSTM\n",
    "        lstm_out, _ = self.lstm(x)                # [B, H, hidden_size]\n",
    "\n",
    "        # 5️⃣ Use last time step (or mean/attention if preferred)\n",
    "        eeg_feat = lstm_out[:, -1, :]\n",
    "        # eeg_feat = lstm_out.mean(dim=1)                    # [B, hidden_size]\n",
    "        # eeg_feat = self.lstm_dense(eeg_feat)\n",
    "\n",
    "        # --- Band features ---\n",
    "        band_feat = self.band_fc(x_band)        # [B, 32]\n",
    "\n",
    "        # --- Fusion ---\n",
    "        fused = torch.cat([eeg_feat, band_feat], dim=1)\n",
    "\n",
    "        # 6️⃣ Fully connected head\n",
    "        x = self.classifier(fused)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def fit(self, train_loader, test_loader, epochs, criterion, optimizer, device, patience=100):\n",
    "        best_val_loss = float('inf')\n",
    "        no_improve = 0\n",
    "\n",
    "        train_losses, train_accs = [], []\n",
    "        val_losses, val_accs     = [], []\n",
    "\n",
    "        best_state = None\n",
    "        for epoch in range(epochs):\n",
    "            # --- Train ---\n",
    "            self.train()\n",
    "            train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "            for xb_eeg, xb_band, yb in train_loader:\n",
    "                xb_eeg = xb_eeg.to(device)\n",
    "                xb_band = xb_band.to(device)\n",
    "                yb = yb.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = self(xb_eeg, xb_band)\n",
    "                loss = criterion(out, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item() * xb_eeg.size(0)\n",
    "                train_correct += (out.argmax(1) == yb).sum().item()\n",
    "                train_total += yb.size(0)\n",
    "\n",
    "            train_loss /= train_total\n",
    "            train_acc  = train_correct / train_total\n",
    "            train_losses.append(train_loss)\n",
    "            train_accs.append(train_acc)\n",
    "\n",
    "            # --- Validate ---\n",
    "            self.eval()\n",
    "            val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "            with torch.no_grad():\n",
    "                for xb_eeg, xb_band, yb in test_loader:\n",
    "                    xb_eeg = xb_eeg.to(device)\n",
    "                    xb_band = xb_band.to(device)\n",
    "                    yb = yb.to(device)\n",
    "                    out = self(xb_eeg, xb_band)\n",
    "                    loss = criterion(out, yb)\n",
    "                    val_loss += loss.item() * xb_eeg.size(0)\n",
    "                    val_correct += (out.argmax(1) == yb).sum().item()\n",
    "                    val_total += yb.size(0)\n",
    "\n",
    "            val_loss /= val_total\n",
    "            val_acc  = val_correct / val_total\n",
    "            val_losses.append(val_loss)\n",
    "            val_accs.append(val_acc)\n",
    "\n",
    "            print(f\"Epoch {epoch+1:03d} | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "                  f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "            # if val_loss - train_loss > 0.2:\n",
    "            #     print(\"Overfitting detected.\")\n",
    "            #     break\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_state = self.state_dict()\n",
    "                no_improve = 0\n",
    "            else:\n",
    "                no_improve += 1\n",
    "                if no_improve >= patience:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    break\n",
    "\n",
    "        if best_state is not None:\n",
    "            self.load_state_dict(best_state)\n",
    "        return {\n",
    "            \"train_accs\": np.array(train_accs),\n",
    "            \"train_losses\": np.array(train_losses),\n",
    "            \"val_accs\":   np.array(val_accs),\n",
    "            \"val_losses\": np.array(val_losses)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ec1eaa-dcab-40b1-a171-1cf366326818",
   "metadata": {},
   "source": [
    "#### **First Model Training**\n",
    "\n",
    "Initial baseline model training with default hyperparameters:\n",
    "\n",
    "**Purpose:**\n",
    "- Establish baseline performance metrics\n",
    "- Verify model architecture and data pipeline\n",
    "- Identify potential issues before hyperparameter optimization\n",
    "\n",
    "**Training Configuration:**\n",
    "- 60 epochs with early stopping\n",
    "- Adam optimizer with L2 regularization\n",
    "- Cross-entropy loss for multi-class classification\n",
    "- Automatic GPU detection and utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f87827b-31e7-417d-b64f-8b93427bc531",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01683741-6af7-471c-8440-c72a1b8fd652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = EEGCNNLSTM().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "history = model.fit(train_loader, test_loader, epochs=60, criterion=criterion,\n",
    "                    optimizer=optimizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ab9a3-cf9a-4fbf-b321-8d29d0797a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for xb_eeg, xb_band, yb in test_loader:\n",
    "        xb_eeg = xb_eeg.to(device)\n",
    "        xb_band = xb_band.to(device)\n",
    "        preds = model(xb_eeg, xb_band).argmax(1).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(yb.numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "print(\"\\nTest Accuracy:\", accuracy_score(all_labels, all_preds))\n",
    "print(classification_report(all_labels, all_preds))\n",
    "print(confusion_matrix(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ba6aae-6a97-4f20-9edd-a31e8d0a355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_accs'], label='Training Accuracy')\n",
    "plt.plot(history['val_accs'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_losses'], label='Training Loss')\n",
    "plt.plot(history['val_losses'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1aae01",
   "metadata": {},
   "source": [
    "#### **Baseline Model Training & Comprehensive Evaluation**\n",
    "\n",
    "Establish baseline performance with unoptimized hyperparameters for comparison:\n",
    "\n",
    "**Purpose:**\n",
    "- Create performance benchmark before hyperparameter optimization\n",
    "- Understand baseline model capabilities and limitations\n",
    "- Identify areas where optimization can provide improvements\n",
    "\n",
    "**Model Configuration (Unoptimized Defaults):**\n",
    "- CNN: 32 kernels per layer, 3x3 kernel size, 0.3 dropout\n",
    "- LSTM: 32 hidden units, 4 layers, 64 dense units\n",
    "- Optimizer: Adam with lr=1e-4, weight_decay=1e-5\n",
    "- Batch size: 64\n",
    "- Early stopping: patience=15\n",
    "\n",
    "**Evaluation Strategy:**\n",
    "1. Train on full train/test split\n",
    "2. Comprehensive metrics: accuracy, precision, recall, F1-score\n",
    "3. Confusion matrix analysis\n",
    "4. Training history visualization\n",
    "5. Model checkpointing for comparison\n",
    "\n",
    "This baseline serves as the reference point for measuring the effectiveness of Bayesian hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038342f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define baseline hyperparameters (unoptimized)\n",
    "baseline_params = {\n",
    "    'cnn_kernels_1': 32,\n",
    "    'cnn_kernel_size_1': 3,\n",
    "    'cnn_kernels_2': 32,\n",
    "    'cnn_kernel_size_2': 3,\n",
    "    'cnn_dropout': 0.3,\n",
    "    'cnn_dense': 16,\n",
    "    'lstm_hidden_size': 32,\n",
    "    'lstm_layers': 4,\n",
    "    'lstm_dense': 64,\n",
    "    'dropout': 0.3,\n",
    "    'learning_rate': 1e-4,\n",
    "    'optimizer': 'adam',\n",
    "    'batch_size': 64\n",
    "}\n",
    "\n",
    "print(\"Baseline Model Hyperparameters:\")\n",
    "print(\"=\"*50)\n",
    "for key, value in baseline_params.items():\n",
    "    print(f\"{key:20s}: {value}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345263bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create baseline model and training components\n",
    "print(\"\\nInitializing baseline model...\")\n",
    "baseline_model = EEGCNNLSTM(\n",
    "    cnn_kernels_1=baseline_params['cnn_kernels_1'],\n",
    "    cnn_kernel_size_1=baseline_params['cnn_kernel_size_1'],\n",
    "    cnn_kernels_2=baseline_params['cnn_kernels_2'],\n",
    "    cnn_kernel_size_2=baseline_params['cnn_kernel_size_2'],\n",
    "    cnn_dropout=baseline_params['cnn_dropout'],\n",
    "    cnn_dense=baseline_params['cnn_dense'],\n",
    "    lstm_hidden_size=baseline_params['lstm_hidden_size'],\n",
    "    lstm_layers=baseline_params['lstm_layers'],\n",
    "    lstm_dense=baseline_params['lstm_dense'],\n",
    "    dropout=baseline_params['dropout']\n",
    ").to(device)\n",
    "\n",
    "# Setup optimizer and loss\n",
    "baseline_optimizer = torch.optim.Adam(\n",
    "    baseline_model.parameters(), \n",
    "    lr=baseline_params['learning_rate'], \n",
    "    weight_decay=1e-5\n",
    ")\n",
    "baseline_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create dataloaders with baseline batch size\n",
    "baseline_train_loader = DataLoader(train_ds, batch_size=baseline_params['batch_size'], shuffle=True)\n",
    "baseline_test_loader = DataLoader(test_ds, batch_size=baseline_params['batch_size'], shuffle=False)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in baseline_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in baseline_model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(\"\\nModel architecture initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2057bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline model\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING BASELINE MODEL (UNOPTIMIZED)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Training for max 100 epochs with early stopping (patience=15)\\n\")\n",
    "\n",
    "baseline_history = baseline_model.fit(\n",
    "    train_loader=baseline_train_loader,\n",
    "    test_loader=baseline_test_loader,\n",
    "    epochs=100,\n",
    "    criterion=baseline_criterion,\n",
    "    optimizer=baseline_optimizer,\n",
    "    device=device,\n",
    "    patience=15\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE TRAINING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total epochs trained: {len(baseline_history['train_losses'])}\")\n",
    "print(f\"Best validation loss: {min(baseline_history['val_losses']):.4f}\")\n",
    "print(f\"Best validation accuracy: {max(baseline_history['val_accs']):.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa550b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive evaluation on test set\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE MODEL - TEST SET EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "baseline_model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb_eeg, xb_band, yb in baseline_test_loader:\n",
    "        xb_eeg = xb_eeg.to(device)\n",
    "        xb_band = xb_band.to(device)\n",
    "        preds = baseline_model(xb_eeg, xb_band).argmax(1).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(yb.numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(all_labels, all_preds)\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "class_report = classification_report(all_labels, all_preds)\n",
    "\n",
    "print(f\"\\nTest Set Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Classification Report:\")\n",
    "print(\"-\"*70)\n",
    "print(class_report)\n",
    "print(\"-\"*70)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"-\"*70)\n",
    "print(conf_matrix)\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9901fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure(figsize=(16, 5))\n",
    "\n",
    "# Plot 1: Accuracy curves\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "epochs = range(1, len(baseline_history['train_accs']) + 1)\n",
    "ax1.plot(epochs, baseline_history['train_accs'], 'b-', label='Training Accuracy', linewidth=2)\n",
    "ax1.plot(epochs, baseline_history['val_accs'], 'r-', label='Validation Accuracy', linewidth=2)\n",
    "ax1.axhline(y=max(baseline_history['val_accs']), color='green', linestyle='--', \n",
    "            alpha=0.5, label=f'Best Val: {max(baseline_history[\"val_accs\"]):.4f}')\n",
    "ax1.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Baseline Model: Accuracy Over Time', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Loss curves\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "ax2.plot(epochs, baseline_history['train_losses'], 'b-', label='Training Loss', linewidth=2)\n",
    "ax2.plot(epochs, baseline_history['val_losses'], 'r-', label='Validation Loss', linewidth=2)\n",
    "ax2.axhline(y=min(baseline_history['val_losses']), color='green', linestyle='--', \n",
    "            alpha=0.5, label=f'Best Val: {min(baseline_history[\"val_losses\"]):.4f}')\n",
    "ax2.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Baseline Model: Loss Over Time', fontsize=14, fontweight='bold')\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Confusion Matrix Heatmap\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=True, \n",
    "            square=True, ax=ax3, cbar_kws={'label': 'Count'})\n",
    "ax3.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Baseline Model: Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Baseline model training and evaluation complete!\")\n",
    "print(f\"✓ Final test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72726c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save baseline results for comparison\n",
    "baseline_results = {\n",
    "    'hyperparameters': baseline_params,\n",
    "    'test_accuracy': float(test_accuracy),\n",
    "    'best_val_accuracy': float(max(baseline_history['val_accs'])),\n",
    "    'best_val_loss': float(min(baseline_history['val_losses'])),\n",
    "    'epochs_trained': len(baseline_history['train_losses']),\n",
    "    'total_parameters': int(total_params),\n",
    "    'trainable_parameters': int(trainable_params),\n",
    "    'confusion_matrix': conf_matrix.tolist(),\n",
    "    'classification_report': class_report\n",
    "}\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE MODEL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Architecture: CNN-LSTM with dual-stream fusion\")\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\"\\nTraining Results:\")\n",
    "print(f\"  Epochs Trained: {len(baseline_history['train_losses'])}\")\n",
    "print(f\"  Best Validation Accuracy: {max(baseline_history['val_accs']):.4f}\")\n",
    "print(f\"  Best Validation Loss: {min(baseline_history['val_losses']):.4f}\")\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"  Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n✓ Baseline results saved for comparison with optimized models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159c22db-c687-481f-8529-b23ffae9a542",
   "metadata": {},
   "source": [
    "#### **Helper Functions**\n",
    "\n",
    "Utility functions for hyperparameter optimization and model evaluation:\n",
    "\n",
    "**Core Functions:**\n",
    "- `batched()`: Iterator utility for creating batches (for cross-validation folds)\n",
    "- `get_timestamp()`: Logging timestamp generation\n",
    "- `get_model()`: Model instantiation with custom hyperparameters\n",
    "- `get_validation()`: Comprehensive model evaluation with metrics\n",
    "- `get_dataset()`: Dynamic dataset creation with configurable batch sizes\n",
    "\n",
    "**Evaluation Metrics:**\n",
    "- Accuracy score\n",
    "- Classification report (precision, recall, F1-score)\n",
    "- Confusion matrix\n",
    "- Cross-validation support\n",
    "\n",
    "These functions enable efficient experimentation and reproducible results across different hyperparameter configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0e739b5-97ce-4907-8c34-e24550813939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def batched(iterable, n, *, strict=False):\n",
    "    # batched('ABCDEFG', 2) → AB CD EF G\n",
    "    if n < 1:\n",
    "        raise ValueError('n must be at least one')\n",
    "    iterator = iter(iterable)\n",
    "    while batch := tuple(itertools.islice(iterator, n)):\n",
    "        if strict and len(batch) != n:\n",
    "            raise ValueError('batched(): incomplete batch')\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49309de8-22a6-422f-a577-69ee748d5178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def get_timestamp():\n",
    "    ts = time.time()\n",
    "    return datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def get_model(params):\n",
    "    model = EEGCNNLSTM(\n",
    "        cnn_kernels_1=params['cnn_kernels_1'],\n",
    "        cnn_kernel_size_1=params['cnn_kernel_size_1'],\n",
    "        cnn_kernels_2=params['cnn_kernels_2'],\n",
    "        cnn_dropout=float(params['cnn_dropout']),\n",
    "        cnn_dense=params['cnn_dense'],\n",
    "        lstm_hidden_size=params['lstm_hidden_size'],\n",
    "        lstm_layers=params['lstm_layers'],\n",
    "        lstm_dense=params['lstm_dense'],\n",
    "        dropout=float(params['cnn_dropout']),  # use cnn_dropout as a simple shared dropout param\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if params['optimizer'] == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'], weight_decay=1e-4)\n",
    "    elif params['optimizer'] == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=params['learning_rate'], weight_decay=1e-4)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=params['learning_rate'], momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    return model, criterion, optimizer\n",
    "\n",
    "def get_validation(model, data_loader, device, matrix=True):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb_eeg, xb_band, yb in data_loader:\n",
    "            xb_eeg = xb_eeg.to(device)\n",
    "            xb_band = xb_band.to(device)\n",
    "            preds = model(xb_eeg, xb_band).argmax(1).cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(yb.numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    report = classification_report(all_labels, all_preds)\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds) if matrix else None\n",
    "\n",
    "    return acc, report, conf_matrix\n",
    "\n",
    "def get_dataset(df, is_train=False, batch_size=36):\n",
    "    frequency_count = len(df['Frequency'].unique())\n",
    "    window_count = len(df['Window'].unique())\n",
    "    numeric_df = df.drop(['ID', 'Window'], axis=1)\n",
    "\n",
    "    # shape: (windows, freqs, features)\n",
    "    full_ndarray = numeric_df.values.reshape((window_count, frequency_count, numeric_df.shape[1]))\n",
    "\n",
    "    X = full_ndarray[:, :, 2:]     # drop ID/Class columns\n",
    "    y = full_ndarray[:, 0, 0]      # class label is repeated across freq rows\n",
    "\n",
    "    # Add channel dimension (N, 1, freq, electrodes)\n",
    "    X = X[..., np.newaxis]          # (N, freq, electrodes, 1)\n",
    "\n",
    "    print(X.shape)\n",
    "\n",
    "    return DataLoader(EEGDataset(X, y), batch_size=batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfcbdbb-a909-4bd8-b736-258d0265d095",
   "metadata": {},
   "source": [
    "#### **Search Space Definition**\n",
    "\n",
    "Hyperparameter search space for Bayesian Optimization using Hyperopt:\n",
    "\n",
    "**CNN Architecture:**\n",
    "- `cnn_kernels_1/2`: Number of convolutional filters [16, 32, 48, 64, 96]\n",
    "- `cnn_kernel_size_1/2`: Kernel dimensions [3x3, 5x5]\n",
    "- `cnn_dropout`: Regularization rate [0.0 - 0.7]\n",
    "- `cnn_dense`: Dense layer size before LSTM [32, 64, 128, 256]\n",
    "\n",
    "**LSTM Architecture:**\n",
    "- `lstm_hidden_size`: Hidden state dimensions [32, 64, 96, 128]\n",
    "- `lstm_layers`: Number of stacked LSTM layers [1-6]\n",
    "- `lstm_dense`: Dense layer size after LSTM [32, 64, 128, 256]\n",
    "\n",
    "**Training Configuration:**\n",
    "- `learning_rate`: Log-uniform distribution [1e-5, 1e-2]\n",
    "- `optimizer`: Choice of Adam, RMSprop, or SGD\n",
    "- `batch_size`: Samples per batch [32, 36, 48, 64, 80, 96]\n",
    "\n",
    "**Optimization Strategy:**\n",
    "Tree-structured Parzen Estimator (TPE) algorithm balances exploration and exploitation to efficiently search the hyperparameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32e30627-801f-426c-985f-887d0b0b04c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK\n",
    "\n",
    "# -------------------------\n",
    "# Hyperopt search space\n",
    "# -------------------------\n",
    "space = {\n",
    "    'cnn_kernels_1'    : hp.choice('cnn_kernels_1', [16, 32, 48, 64]),\n",
    "    'cnn_kernel_size_1': hp.choice('cnn_kernel_size_1', [3, 5]),\n",
    "    'cnn_kernels_2'    : hp.choice('cnn_kernels_2', [16, 32, 64, 96]),\n",
    "    'cnn_kernel_size_2': hp.choice('cnn_kernel_size_2', [3, 5]),\n",
    "    'cnn_dropout'      : hp.uniform('cnn_dropout', 0.0, 0.7),\n",
    "    'cnn_dense'        : hp.choice('cnn_dense', [32, 64, 128, 256]),\n",
    "    'lstm_hidden_size' : hp.choice('lstm_hidden_size', [32, 64, 96, 128]),\n",
    "    'lstm_layers'      : hp.choice('lstm_layers', [1, 2, 3, 4, 5, 6]),\n",
    "    'lstm_dense'       : hp.choice('lstm_dense', [32, 64, 128, 256]),\n",
    "    'learning_rate'    : hp.loguniform('learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'optimizer'        : hp.choice('optimizer', ['adam', 'rmsprop', 'sgd']),\n",
    "    'batch_size'       : hp.choice('batch_size', [32, 36, 48, 64, 80, 96])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3db2be-a073-42a6-9466-4468ebd16381",
   "metadata": {},
   "source": [
    "#### **Search Objective Definition**\n",
    "\n",
    "Objective function for Hyperopt optimization with two strategies:\n",
    "\n",
    "### Strategy 1: K-Fold Cross-Validation (Commented)\n",
    "**Approach:**\n",
    "- Subject-stratified K-fold cross-validation\n",
    "- Cyclic fold generation for balanced distribution\n",
    "- Score calculation: `mean_loss + variance_of_tail_losses`\n",
    "- More robust but computationally expensive\n",
    "\n",
    "**Metrics:**\n",
    "- Mean validation loss across all folds\n",
    "- Variance of final validation losses (stability measure)\n",
    "- Combined score penalizes both high loss and instability\n",
    "\n",
    "### Strategy 2: Single Train/Test Split (Active)\n",
    "**Approach:**\n",
    "- Uses predefined train/test split\n",
    "- Faster iteration for initial hyperparameter search\n",
    "- Early stopping with patience=10\n",
    "\n",
    "**Return Value:**\n",
    "- Minimizes best validation loss\n",
    "- Includes training history for analysis\n",
    "- STATUS_OK for successful trials\n",
    "\n",
    "**Note:** The objective function is called by Hyperopt's `fmin()` and should return a dictionary with 'loss' and 'status' keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69653680-cc67-4a43-9456-5551beeed641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# -------------------------\n",
    "# k-Fold CV for Hyperopt\n",
    "# -------------------------\n",
    "def objective(params):\n",
    "    print(\"Trial params:\", params)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    unique_subjects = df['ID'].unique()\n",
    "    losses = []\n",
    "    variances = []\n",
    "    batch_size = params['batch_size']\n",
    "\n",
    "    K_FOLDS = 5\n",
    "    fold_size = len(unique_subjects) // K_FOLDS\n",
    "\n",
    "    cyclic = itertools.cycle(unique_subjects)\n",
    "    batched_cyclic = batched(cyclic, n=fold_size)\n",
    "    folds = itertools.islice(batched_cyclic, K_FOLDS)\n",
    "\n",
    "    for i, fold in enumerate(folds):\n",
    "        print(f\"Starting fold {i + 1}/{K_FOLDS}\")\n",
    "\n",
    "        train_df = df[~df['ID'].isin(fold)]\n",
    "        test_df  = df[df['ID'].isin(fold)]\n",
    "\n",
    "        print(train_df.shape, test_df.shape)\n",
    "\n",
    "        train_loader = get_dataset(train_df, batch_size=batch_size)\n",
    "        test_loader  = get_dataset(test_df, batch_size=batch_size)\n",
    "        model, criterion, optimizer = get_model(params)\n",
    "\n",
    "        # Train with modest epochs; early stopping inside fit handles rest\n",
    "        history = model.fit(\n",
    "            train_loader=train_loader,\n",
    "            test_loader=test_loader,\n",
    "            epochs=60,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            patience=15\n",
    "        )\n",
    "\n",
    "        acc, *_ = get_validation(model, test_loader, device)\n",
    "        loss = history['val_losses']\n",
    "        mean_loss = np.min(loss)\n",
    "        losses.append(mean_loss)\n",
    "\n",
    "        last_5_or_less = history[\"val_losses\"]\n",
    "        last_5_or_less = last_5_or_less[-min(len(last_5_or_less), 5):]\n",
    "        variance = np.var(last_5_or_less) if len(last_5_or_less) > 1 else 1\n",
    "        variances.append(variance)\n",
    "\n",
    "        print(f\"Fold {i + 1} Accuracy:\", acc)\n",
    "\n",
    "    loss = np.mean(losses)\n",
    "    tail_variance = np.var(variances)\n",
    "    print(variances)\n",
    "    score = loss + tail_variance\n",
    "\n",
    "    print(f\"k-Fold CV Mean Loss: {loss:.4f} ± {np.std(losses):.4f}\")\n",
    "    print(f\"k-Fold CV Tail Variance: {tail_variance:.4f}\")\n",
    "\n",
    "    # Hyperopt minimizes -> return negative accuracy\n",
    "    return {'loss': score, 'status': STATUS_OK, 'attachments': {'history': history}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fdbeed8-2f69-45bb-b4ee-d5e73b4c2f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Single Objective for Hyperopt\n",
    "# -------------------------\n",
    "def objective(params):\n",
    "    print(\"Trial params:\", params)\n",
    "\n",
    "    # build dataloaders from the existing train_ds/test_ds in this session\n",
    "    train_loader = DataLoader(train_ds, batch_size=params['batch_size'], shuffle=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=params['batch_size'], shuffle=False)\n",
    "\n",
    "    # create model (note we pass dropout into lstm dropout and cnn dropout)\n",
    "    model, criterion, optimizer = get_model(params)\n",
    "\n",
    "    # Train with modest epochs; early stopping inside fit handles rest\n",
    "    history = model.fit(\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        epochs=60,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        patience=10\n",
    "    )\n",
    "\n",
    "    best_val_loss = float(np.min(history['val_losses'])) if len(history['val_losses']) > 0 else 0.0\n",
    "\n",
    "    # Hyperopt minimizes -> return negative accuracy\n",
    "    return {'loss': best_val_loss, 'status': STATUS_OK, 'attachments': {'history': history, 'best_val_loss': best_val_loss}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bbef8d-8af5-4fbc-bf88-ad2a8ae921af",
   "metadata": {},
   "source": [
    "#### **Hyperparameter Search**\n",
    "\n",
    "Execute Tree-structured Parzen Estimator (TPE) search for optimal hyperparameters:\n",
    "\n",
    "**Search Configuration:**\n",
    "- `max_evals`: Number of trials (default: 30, increase for thorough search)\n",
    "- Algorithm: TPE (adaptive Bayesian optimization)\n",
    "- Tracks all trials in Hyperopt Trials object\n",
    "\n",
    "**Process:**\n",
    "1. Initialize trials tracking object\n",
    "2. Run TPE algorithm over search space\n",
    "3. Convert raw indices to interpretable values\n",
    "4. Save best parameters to JSON\n",
    "\n",
    "**Output:**\n",
    "- **Best hyperparameters**: Both raw indices and interpreted values\n",
    "- **Search duration**: Total optimization time\n",
    "- **Parameters JSON**: Serialized configuration for model reproduction\n",
    "\n",
    "**Multiple Runs:**\n",
    "The second cell executes 10 independent search runs to:\n",
    "- Assess hyperparameter sensitivity\n",
    "- Identify robust configurations\n",
    "- Build ensemble of candidate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086894b3-97e9-4755-9b94-886320886f39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import Trials, fmin\n",
    "\n",
    "def hyperparameter_search(max_evals=30, seed=None):\n",
    "    trials = Trials()\n",
    "    \n",
    "    # Create seeded random state for Hyperopt\n",
    "    rstate = np.random.RandomState(seed) if seed is not None else None\n",
    "    \n",
    "    print(\"Starting TPE search...\")\n",
    "    if seed is not None:\n",
    "        print(f\"Using seed: {seed}\")\n",
    "    t0 = time.time()\n",
    "    best = fmin(\n",
    "        fn=objective,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=max_evals,   # increase for more thorough search\n",
    "        trials=trials,\n",
    "        rstate=rstate  # CRITICAL: seed Hyperopt's random state\n",
    "    )\n",
    "    \n",
    "    print(\"Best hyperparameters:\", best)\n",
    "    t1 = time.time()\n",
    "    duration = t1 - t0\n",
    "    print(f\"TPE search finished in {duration:.2f} seconds\")\n",
    "    print(\"Best (raw indices):\", best)\n",
    "    \n",
    "    # Convert choice indices back to values for readability:\n",
    "    def choice_value(key, val):\n",
    "        mapping = {\n",
    "            'cnn_kernels_1': [16, 32, 48, 64],\n",
    "            'cnn_kernel_size_1': [3, 5],\n",
    "            'cnn_kernels_2': [16, 32, 64, 96],\n",
    "            'cnn_kernel_size_2': [3, 5],\n",
    "            'cnn_dense': [32, 64, 128, 256],\n",
    "            'lstm_hidden_size': [32, 64, 96, 128],\n",
    "            'lstm_layers': [1, 2, 3, 4, 5, 6],\n",
    "            'lstm_dense': [32, 64, 128, 256],\n",
    "            'optimizer': ['adam', 'rmsprop', 'sgd'],\n",
    "            'batch_size': [32, 36, 48, 64, 80, 96]\n",
    "        }\n",
    "        return mapping[key][int(val)] if key in mapping else val\n",
    "    \n",
    "    readable = {k: choice_value(k, v) if k in ['cnn_kernels_1','cnn_kernel_size_1','cnn_kernels_2',\n",
    "                                               'cnn_kernel_size_2', 'cnn_dense','lstm_hidden_size',\n",
    "                                               'lstm_layers','lstm_dense','optimizer','batch_size'] else v\n",
    "                for k,v in best.items()}\n",
    "    print(\"Best (interpreted):\", readable)\n",
    "\n",
    "    params = dict(readable)\n",
    "    params['cnn_kernels_1'] = int(params['cnn_kernels_1'])\n",
    "    params['cnn_kernel_size_1'] = int(params['cnn_kernel_size_1'])\n",
    "    params['cnn_kernels_2'] = int(params['cnn_kernels_2'])\n",
    "    params['cnn_kernel_size_2'] = int(params['cnn_kernel_size_2'])\n",
    "    params['cnn_dense'] = int(params['cnn_dense'])\n",
    "    params['lstm_hidden_size'] = int(params['lstm_hidden_size'])\n",
    "    params['lstm_layers'] = int(params['lstm_layers'])\n",
    "    params['lstm_dense'] = int(params['lstm_dense'])\n",
    "    params['batch_size'] = int(params['batch_size'])\n",
    "    params['cnn_dropout'] = float(params['cnn_dropout'])\n",
    "    params['dropout'] = float(params['cnn_dropout'])\n",
    "\n",
    "    return trials, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f549aa-3b7b-4bce-bd19-460597af1f5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trials, params = hyperparameter_search()\n",
    "with open(\"best_parameters.json\", \"w+\") as f:\n",
    "    import json\n",
    "    json.dump(params, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0526fe-c2b6-44b6-801c-b85489073f88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trial_results = []\n",
    "\n",
    "for i in range(10):\n",
    "    trials, params = hyperparameter_search()\n",
    "    trial_results.append({\"trials\": trials, \"params\": params})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3309ea-f41e-4d51-a860-176d3821da54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def to_json_safe(obj):\n",
    "    \"\"\"Recursively convert objects to JSON-serializable types.\"\"\"\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    if isinstance(obj, (np.float32, np.float64)):\n",
    "        return float(obj)\n",
    "    if isinstance(obj, (np.int32, np.int64)):\n",
    "        return int(obj)\n",
    "    if isinstance(obj, datetime):\n",
    "        return obj.isoformat()\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: to_json_safe(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [to_json_safe(v) for v in obj]\n",
    "    return obj\n",
    "\n",
    "\n",
    "def serialize_trial(trial):\n",
    "    \"\"\"Extract only JSON-safe and meaningful parts of a Hyperopt Trial.\"\"\"\n",
    "    print(trial.attachments)\n",
    "    return {\n",
    "        \"attachments\": to_json_safe(trial.attachments)\n",
    "    }\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# DROP-IN REPLACEMENT STARTS HERE\n",
    "# ===============================\n",
    "\n",
    "json_results = []\n",
    "\n",
    "for entry in trial_results:\n",
    "    json_results.append({\n",
    "        \"params\": to_json_safe(entry.get(\"params\")),\n",
    "        \"trial\": serialize_trial(entry.get(\"trials\")),\n",
    "    })\n",
    "\n",
    "with open(\"all_trials.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(\n",
    "        {\"results\": json_results},\n",
    "        f,\n",
    "        indent=4,\n",
    "        ensure_ascii=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ffed76",
   "metadata": {},
   "source": [
    "#### **Results Visualization**\n",
    "\n",
    "Comprehensive hyperparameter optimization with iterative Bayesian Optimization and convergence tracking:\n",
    "\n",
    "---\n",
    "\n",
    "### **Iterative Convergence-Based Bayesian Optimization**\n",
    "\n",
    "**Multi-Run Strategy:**\n",
    "- Starts with 3 initial BO searches with different random seeds\n",
    "- Runs 2 additional iterations and recalculates standard deviation\n",
    "- Continues until std dev stabilizes (relative change < 0.1%)\n",
    "- Tracks convergence to ensure robust hyperparameter selection\n",
    "\n",
    "**Reproducibility:**\n",
    "- Each BO run uses a unique sequential seed (base_seed + run_index)\n",
    "- Seeds control PyTorch, NumPy, Python random states, and Hyperopt's TPE sampler\n",
    "- Full seed tracking for experiment reproduction\n",
    "\n",
    "**Stability Criteria:**\n",
    "- Convergence: `|current_std - previous_std| / previous_std < 0.001`\n",
    "- Reduces sensitivity to random initialization\n",
    "- Ensures identified hyperparameters are stable across multiple searches\n",
    "\n",
    "**Safety Measures:**\n",
    "- Maximum limit of 20 total BO runs\n",
    "- Prevents infinite loops while allowing thorough exploration\n",
    "\n",
    "---\n",
    "\n",
    "### **Comprehensive Visualization and Analysis**\n",
    "\n",
    "**Performance Summary:**\n",
    "- Table of all BO runs with seeds and validation losses\n",
    "- Ranking of configurations by performance\n",
    "- Statistical analysis: mean, std dev, min/max, range\n",
    "\n",
    "**Convergence Plots:**\n",
    "- Best validation loss across all runs (bar chart with annotations)\n",
    "- Standard deviation evolution over iterations\n",
    "- Percentage change annotations between measurements\n",
    "- Color-coded convergence indicators (green when < 0.1% change)\n",
    "\n",
    "**Visual Highlights:**\n",
    "- Best performing run highlighted in green\n",
    "- Mean and minimum loss reference lines\n",
    "- Convergence threshold visualization\n",
    "\n",
    "---\n",
    "\n",
    "### **Best Parameters Extraction**\n",
    "\n",
    "**Selection Process:**\n",
    "- Systematically searches across all BO runs\n",
    "- Identifies trial with lowest validation loss\n",
    "- Extracts complete hyperparameter configuration\n",
    "\n",
    "**Output:**\n",
    "- Best run index and seed for reproducibility\n",
    "- Complete hyperparameter dictionary\n",
    "- Best validation loss achieved\n",
    "- Saves to `best_parameters.json` for deployment\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Model Training with Optimal Hyperparameters**\n",
    "\n",
    "**Evaluation:**\n",
    "- Trains model with best discovered hyperparameters\n",
    "- Reports test set accuracy, classification report, confusion matrix\n",
    "- Visualizes training history (accuracy and loss curves)\n",
    "- Confirms model generalization performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faee892-23fa-430f-8bde-2e9ff855827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def run_bo_with_seed(seed, max_evals=30):\n",
    "    \"\"\"Run Bayesian Optimization with a specific seed.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running BO with seed: {seed}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    set_seed(seed)\n",
    "    # CRITICAL: Pass seed to hyperparameter_search to seed Hyperopt\n",
    "    trials, params = hyperparameter_search(max_evals=max_evals, seed=seed)\n",
    "    \n",
    "    # Extract best validation loss from this run\n",
    "    best_val_loss = float('inf')\n",
    "    for trial in trials.trials:\n",
    "        if trial['result']['status'] == 'ok':\n",
    "            loss = trial['result']['loss']\n",
    "            if loss < best_val_loss:\n",
    "                best_val_loss = loss\n",
    "    \n",
    "    return {\n",
    "        'seed': seed,\n",
    "        'trials': trials,\n",
    "        'params': params,\n",
    "        'best_val_loss': best_val_loss\n",
    "    }\n",
    "\n",
    "# Initialize tracking variables\n",
    "all_bo_runs = []\n",
    "std_devs = []\n",
    "run_counts = []  # Track number of runs for each std_dev calculation\n",
    "base_seed = 42\n",
    "\n",
    "print(\"Starting iterative Bayesian Optimization with convergence tracking...\")\n",
    "print(f\"Convergence criterion: Standard deviation change < 0.1%\\n\")\n",
    "\n",
    "# Initial 3 runs\n",
    "print(\"Phase 1: Running initial 3 BO searches...\")\n",
    "for i in range(3):\n",
    "    seed = base_seed + i\n",
    "    result = run_bo_with_seed(seed, max_evals=30)\n",
    "    all_bo_runs.append(result)\n",
    "    \n",
    "    print(f\"\\nRun {i+1}/3 completed:\")\n",
    "    print(f\"  Seed: {seed}\")\n",
    "    print(f\"  Best Val Loss: {result['best_val_loss']:.6f}\")\n",
    "\n",
    "# Calculate std dev only after all 3 initial runs\n",
    "best_losses = [r['best_val_loss'] for r in all_bo_runs]\n",
    "current_std = np.std(best_losses)\n",
    "std_devs.append(current_std)\n",
    "run_counts.append(len(all_bo_runs))\n",
    "\n",
    "print(f\"\\nPhase 1 Summary:\")\n",
    "print(f\"  Total Runs: {len(all_bo_runs)}\")\n",
    "print(f\"  Std Dev: {current_std:.6f}\")\n",
    "\n",
    "# Iterative refinement\n",
    "iteration = 2\n",
    "converged = False\n",
    "prev_std = std_devs[-1]\n",
    "\n",
    "while not converged:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase {iteration}: Running 2 additional BO searches...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Run 2 more BO searches\n",
    "    for i in range(2):\n",
    "        seed = base_seed + len(all_bo_runs)\n",
    "        result = run_bo_with_seed(seed, max_evals=30)\n",
    "        all_bo_runs.append(result)\n",
    "        \n",
    "        print(f\"\\nRun {len(all_bo_runs)} completed:\")\n",
    "        print(f\"  Seed: {seed}\")\n",
    "        print(f\"  Best Val Loss: {result['best_val_loss']:.6f}\")\n",
    "    \n",
    "    # Calculate new std dev after both runs complete\n",
    "    best_losses = [r['best_val_loss'] for r in all_bo_runs]\n",
    "    current_std = np.std(best_losses)\n",
    "    std_devs.append(current_std)\n",
    "    run_counts.append(len(all_bo_runs))\n",
    "    \n",
    "    # Check convergence\n",
    "    std_change = abs(current_std - prev_std) / prev_std if prev_std > 0 else 1.0\n",
    "    \n",
    "    print(f\"\\n--- Convergence Check ---\")\n",
    "    print(f\"Total Runs:       {len(all_bo_runs)}\")\n",
    "    print(f\"Previous Std Dev: {prev_std:.6f}\")\n",
    "    print(f\"Current Std Dev:  {current_std:.6f}\")\n",
    "    print(f\"Relative Change:  {std_change*100:.4f}%\")\n",
    "    \n",
    "    if std_change < 0.001:  # 0.1% threshold\n",
    "        print(f\"\\n✓ Convergence achieved! Std dev change < 0.1%\")\n",
    "        converged = True\n",
    "    else:\n",
    "        print(f\"\\n→ Not converged yet, continuing...\")\n",
    "        prev_std = current_std\n",
    "        iteration += 1\n",
    "        \n",
    "        # Safety limit\n",
    "        if len(all_bo_runs) >= 20:\n",
    "            print(f\"\\n⚠ Reached maximum of 20 runs, stopping.\")\n",
    "            converged = True\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Optimization Complete!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total BO runs: {len(all_bo_runs)}\")\n",
    "print(f\"Final Std Dev: {std_devs[-1]:.6f}\")\n",
    "print(f\"Std Dev tracked at runs: {run_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc72a561-4b54-4c8d-bc7d-73e9040c385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Create summary table\n",
    "summary_data = []\n",
    "for i, run in enumerate(all_bo_runs):\n",
    "    summary_data.append({\n",
    "        'Run': i + 1,\n",
    "        'Seed': run['seed'],\n",
    "        'Best Val Loss': run['best_val_loss'],\n",
    "        'Rank': 0  # Will be filled after sorting\n",
    "    })\n",
    "\n",
    "# Sort by best val loss and assign ranks\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.sort_values('Best Val Loss')\n",
    "summary_df['Rank'] = range(1, len(summary_df) + 1)\n",
    "summary_df = summary_df.sort_values('Run')  # Resort by run order\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY OF BAYESIAN OPTIMIZATION RUNS\")\n",
    "print(\"=\"*70)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate statistics\n",
    "mean_loss = summary_df['Best Val Loss'].mean()\n",
    "std_loss = summary_df['Best Val Loss'].std()\n",
    "min_loss = summary_df['Best Val Loss'].min()\n",
    "max_loss = summary_df['Best Val Loss'].max()\n",
    "\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"  Mean Best Loss: {mean_loss:.6f}\")\n",
    "print(f\"  Std Dev:        {std_loss:.6f}\")\n",
    "print(f\"  Min Loss:       {min_loss:.6f}\")\n",
    "print(f\"  Max Loss:       {max_loss:.6f}\")\n",
    "print(f\"  Range:          {max_loss - min_loss:.6f}\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Best validation losses across runs\n",
    "ax1 = axes[0]\n",
    "runs = summary_df['Run'].values\n",
    "losses = summary_df['Best Val Loss'].values\n",
    "colors = ['#2ecc71' if loss == min_loss else '#3498db' for loss in losses]\n",
    "\n",
    "bars = ax1.bar(runs, losses, color=colors, alpha=0.7, edgecolor='black', linewidth=1.2)\n",
    "ax1.axhline(y=mean_loss, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_loss:.4f}')\n",
    "ax1.axhline(y=min_loss, color='green', linestyle='--', linewidth=2, alpha=0.5, label=f'Best: {min_loss:.4f}')\n",
    "\n",
    "ax1.set_xlabel('BO Run', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Best Validation Loss', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Best Validation Loss per BO Run', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.set_xticks(runs)\n",
    "\n",
    "# Annotate the best run\n",
    "best_run_idx = summary_df['Best Val Loss'].idxmin()\n",
    "best_run = summary_df.loc[best_run_idx, 'Run']\n",
    "best_loss = summary_df.loc[best_run_idx, 'Best Val Loss']\n",
    "ax1.annotate(f'Best\\n{best_loss:.4f}', \n",
    "             xy=(best_run, best_loss),\n",
    "             xytext=(best_run, best_loss + (max_loss - min_loss) * 0.1),\n",
    "             ha='center',\n",
    "             fontsize=9,\n",
    "             fontweight='bold',\n",
    "             color='darkgreen',\n",
    "             arrowprops=dict(arrowstyle='->', color='darkgreen', lw=1.5))\n",
    "\n",
    "# Plot 2: Standard deviation convergence\n",
    "ax2 = axes[1]\n",
    "\n",
    "# Use the tracked run_counts for accurate x-axis\n",
    "ax2.plot(run_counts, std_devs, marker='o', linewidth=2.5, markersize=8, \n",
    "         color='#e74c3c', markerfacecolor='white', markeredgewidth=2)\n",
    "ax2.set_xlabel('Number of BO Runs', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Std Dev of Best Losses', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Convergence of Standard Deviation', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add convergence threshold line\n",
    "if len(std_devs) > 1:\n",
    "    converged_std = std_devs[-1]\n",
    "    ax2.axhline(y=converged_std, color='green', linestyle='--', linewidth=2, \n",
    "                alpha=0.5, label=f'Final: {converged_std:.4f}')\n",
    "    ax2.legend(fontsize=10)\n",
    "\n",
    "# Annotate percentage changes between consecutive measurements\n",
    "for i in range(1, len(std_devs)):\n",
    "    pct_change = abs(std_devs[i] - std_devs[i-1]) / std_devs[i-1] * 100 if std_devs[i-1] > 0 else 0\n",
    "    mid_x = (run_counts[i] + run_counts[i-1]) / 2\n",
    "    mid_y = (std_devs[i] + std_devs[i-1]) / 2\n",
    "    \n",
    "    # Color code: red if change > 0.1%, green if <= 0.1%\n",
    "    box_color = 'lightgreen' if pct_change <= 0.1 else 'yellow'\n",
    "    \n",
    "    ax2.annotate(f'{pct_change:.2f}%', \n",
    "                xy=(mid_x, mid_y),\n",
    "                fontsize=8,\n",
    "                ha='center',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor=box_color, alpha=0.5, edgecolor='gray'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Visualization complete.\")\n",
    "print(f\"\\nConvergence History:\")\n",
    "for i, (runs, std) in enumerate(zip(run_counts, std_devs)):\n",
    "    if i == 0:\n",
    "        print(f\"  After {runs} runs: Std Dev = {std:.6f}\")\n",
    "    else:\n",
    "        prev_std = std_devs[i-1]\n",
    "        pct_change = abs(std - prev_std) / prev_std * 100 if prev_std > 0 else 0\n",
    "        status = \"✓ Converged\" if pct_change < 0.1 else \"→ Continuing\"\n",
    "        print(f\"  After {runs} runs: Std Dev = {std:.6f} (Change: {pct_change:.2f}%) {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7356bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def extract_best_params_from_runs(all_runs):\n",
    "    \"\"\"Extract parameters from the best performing BO run.\"\"\"\n",
    "    best_overall_loss = float('inf')\n",
    "    best_params = None\n",
    "    best_run_index = -1\n",
    "    best_seed = None\n",
    "    \n",
    "    for run_idx, run_data in enumerate(all_runs):\n",
    "        if run_data['best_val_loss'] < best_overall_loss:\n",
    "            best_overall_loss = run_data['best_val_loss']\n",
    "            best_params = run_data['params']\n",
    "            best_run_index = run_idx + 1\n",
    "            best_seed = run_data['seed']\n",
    "    \n",
    "    if best_params:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"BEST PERFORMING CONFIGURATION\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Run Index:        {best_run_index}/{len(all_runs)}\")\n",
    "        print(f\"Seed:             {best_seed}\")\n",
    "        print(f\"Best Val Loss:    {best_overall_loss:.6f}\")\n",
    "        print(f\"\\nHyperparameters:\")\n",
    "        print(json.dumps(best_params, indent=4))\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Save best parameters\n",
    "        output_data = {\n",
    "            'run_index': best_run_index,\n",
    "            'seed': best_seed,\n",
    "            'best_val_loss': float(best_overall_loss),\n",
    "            'parameters': best_params\n",
    "        }\n",
    "        \n",
    "        with open(\"best_parameters.json\", \"w\") as f:\n",
    "            json.dump(output_data, f, indent=4)\n",
    "        \n",
    "        print(f\"\\n✓ Best parameters saved to 'best_parameters.json'\")\n",
    "        \n",
    "        return best_params\n",
    "    else:\n",
    "        print(\"Error: No valid parameters found.\")\n",
    "        return None\n",
    "\n",
    "# Extract best parameters from all BO runs\n",
    "best_params = extract_best_params_from_runs(all_bo_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6535bb83-2d15-43e5-b0c9-3c628a4c9201",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build dataloaders from the existing train_ds/test_ds in this session\n",
    "train_loader = DataLoader(train_ds, batch_size=best_params['batch_size'], shuffle=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=best_params['batch_size'], shuffle=False)\n",
    "\n",
    "# create model (note we pass dropout into lstm dropout and cnn dropout)\n",
    "model, criterion, optimizer = get_model(best_params)\n",
    "\n",
    "# Train with modest epochs; early stopping inside fit handles rest\n",
    "history = model.fit(\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=60,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    patience=10\n",
    ")\n",
    "acc, report, matrix = get_validation(model, test_loader, device)\n",
    "\n",
    "print(\"\\nval Accuracy:\", acc)\n",
    "print(report)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d952c1-9d35-4bc1-bf41-942e5dddab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_accs'], label='Training Accuracy')\n",
    "plt.plot(history['val_accs'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_losses'], label='Training Loss')\n",
    "plt.plot(history['val_losses'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10af9fa3",
   "metadata": {},
   "source": [
    "#### **Model Architecture Visualization with TorchViz**\n",
    "\n",
    "Visualize the computational graph structure of both models to understand:\n",
    "- Forward pass data flow and operations\n",
    "- Layer connectivity and tensor transformations\n",
    "- Architectural differences between baseline and optimized models\n",
    "- Parameter sharing and gradient flow paths\n",
    "\n",
    "**TorchViz** generates graphical representations of PyTorch computational graphs, making it easy to:\n",
    "- Debug model architecture\n",
    "- Identify bottlenecks or unnecessary operations\n",
    "- Compare different architectural configurations\n",
    "- Understand how hyperparameter changes affect model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f0e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install torchviz if not already available\n",
    "try:\n",
    "    from torchviz import make_dot\n",
    "    print(\"✓ torchviz already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing torchviz...\")\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install torchviz graphviz -q\n",
    "    from torchviz import make_dot\n",
    "    print(\"✓ torchviz installed successfully\")\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "\n",
    "print(\"✓ TorchViz ready for model visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b0f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample from test set for graph generation\n",
    "baseline_model.eval()\n",
    "model.eval()\n",
    "\n",
    "# Get first batch from test loader\n",
    "sample_batch = next(iter(baseline_test_loader))\n",
    "sample_x_eeg = sample_batch[0][0:1].to(device)  # First sample only\n",
    "sample_x_band = sample_batch[1][0:1].to(device)\n",
    "sample_label = sample_batch[2][0].item()\n",
    "\n",
    "print(f\"✓ Sample selected for visualization (label: {sample_label})\")\n",
    "print(f\"  EEG shape: {sample_x_eeg.shape}\")\n",
    "print(f\"  Band features shape: {sample_x_band.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409f5d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate computational graph for baseline model\n",
    "print(\"Generating computational graph for BASELINE model...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Forward pass to create computation graph\n",
    "baseline_output = baseline_model(sample_x_eeg, sample_x_band)\n",
    "\n",
    "# Create visualization\n",
    "baseline_graph = make_dot(\n",
    "    baseline_output.mean(), \n",
    "    params=dict(baseline_model.named_parameters()),\n",
    "    show_attrs=True,\n",
    "    show_saved=False\n",
    ")\n",
    "\n",
    "# Customize graph appearance\n",
    "baseline_graph.graph_attr.update({\n",
    "    'rankdir': 'TB',  # Top to Bottom\n",
    "    'size': '12,16',\n",
    "    'dpi': '150',\n",
    "    'bgcolor': 'white',\n",
    "    'label': 'Baseline (Unoptimized) CNN-LSTM Model Architecture',\n",
    "    'labelloc': 't',\n",
    "    'fontsize': '20',\n",
    "    'fontname': 'Arial Bold'\n",
    "})\n",
    "\n",
    "baseline_graph.node_attr.update({\n",
    "    'style': 'filled',\n",
    "    'fillcolor': 'lightblue',\n",
    "    'fontname': 'Arial',\n",
    "    'fontsize': '10'\n",
    "})\n",
    "\n",
    "# Render and display\n",
    "baseline_graph.render('baseline_model_graph', format='png', cleanup=True)\n",
    "print(\"✓ Baseline model graph saved as 'baseline_model_graph.png'\")\n",
    "\n",
    "# Display in notebook\n",
    "from IPython.display import Image, display\n",
    "display(Image('baseline_model_graph.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc8ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate computational graph for optimized model\n",
    "print(\"\\nGenerating computational graph for OPTIMIZED model...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Forward pass to create computation graph\n",
    "optimized_output = model(sample_x_eeg, sample_x_band)\n",
    "\n",
    "# Create visualization\n",
    "optimized_graph = make_dot(\n",
    "    optimized_output.mean(), \n",
    "    params=dict(model.named_parameters()),\n",
    "    show_attrs=True,\n",
    "    show_saved=False\n",
    ")\n",
    "\n",
    "# Customize graph appearance\n",
    "optimized_graph.graph_attr.update({\n",
    "    'rankdir': 'TB',  # Top to Bottom\n",
    "    'size': '12,16',\n",
    "    'dpi': '150',\n",
    "    'bgcolor': 'white',\n",
    "    'label': 'Optimized CNN-LSTM Model Architecture',\n",
    "    'labelloc': 't',\n",
    "    'fontsize': '20',\n",
    "    'fontname': 'Arial Bold'\n",
    "})\n",
    "\n",
    "optimized_graph.node_attr.update({\n",
    "    'style': 'filled',\n",
    "    'fillcolor': 'lightcoral',\n",
    "    'fontname': 'Arial',\n",
    "    'fontsize': '10'\n",
    "})\n",
    "\n",
    "# Render and display\n",
    "optimized_graph.render('optimized_model_graph', format='png', cleanup=True)\n",
    "print(\"✓ Optimized model graph saved as 'optimized_model_graph.png'\")\n",
    "\n",
    "# Display in notebook\n",
    "display(Image('optimized_model_graph.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8d26cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Architecture and Parameter Comparison\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DETAILED ARCHITECTURE & PARAMETER COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def get_layer_info(model, model_name):\n",
    "    \"\"\"Extract detailed layer information from model.\"\"\"\n",
    "    layer_info = []\n",
    "    \n",
    "    for name, module in model.named_modules():\n",
    "        if len(list(module.children())) == 0 and name:  # Leaf modules only\n",
    "            params = sum(p.numel() for p in module.parameters())\n",
    "            trainable = sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "            \n",
    "            # Get layer type and shape info\n",
    "            layer_type = module.__class__.__name__\n",
    "            \n",
    "            # Get specific attributes based on layer type\n",
    "            details = \"\"\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                details = f\"in={module.in_channels}, out={module.out_channels}, kernel={module.kernel_size}\"\n",
    "            elif isinstance(module, nn.Linear):\n",
    "                details = f\"in={module.in_features}, out={module.out_features}\"\n",
    "            elif isinstance(module, nn.LSTM):\n",
    "                details = f\"input={module.input_size}, hidden={module.hidden_size}, layers={module.num_layers}\"\n",
    "            elif isinstance(module, nn.Dropout):\n",
    "                details = f\"p={module.p}\"\n",
    "            elif isinstance(module, nn.AvgPool2d):\n",
    "                details = f\"kernel={module.kernel_size}\"\n",
    "            \n",
    "            layer_info.append({\n",
    "                'name': name,\n",
    "                'type': layer_type,\n",
    "                'details': details,\n",
    "                'total_params': params,\n",
    "                'trainable_params': trainable\n",
    "            })\n",
    "    \n",
    "    return layer_info\n",
    "\n",
    "# Get layer information for both models\n",
    "baseline_layers = get_layer_info(baseline_model, \"Baseline\")\n",
    "optimized_layers = get_layer_info(model, \"Optimized\")\n",
    "\n",
    "# Create comparison DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "baseline_df = pd.DataFrame(baseline_layers)\n",
    "optimized_df = pd.DataFrame(optimized_layers)\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"BASELINE (UNOPTIMIZED) MODEL ARCHITECTURE\")\n",
    "print(\"-\"*70)\n",
    "print(baseline_df.to_string(index=False))\n",
    "print(f\"\\nTotal Parameters: {baseline_df['total_params'].sum():,}\")\n",
    "print(f\"Trainable Parameters: {baseline_df['trainable_params'].sum():,}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"OPTIMIZED MODEL ARCHITECTURE\")\n",
    "print(\"-\"*70)\n",
    "print(optimized_df.to_string(index=False))\n",
    "print(f\"\\nTotal Parameters: {optimized_df['total_params'].sum():,}\")\n",
    "print(f\"Trainable Parameters: {optimized_df['trainable_params'].sum():,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73f3758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual Comparison of Key Architectural Differences\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Extract key hyperparameters for comparison\n",
    "baseline_hp = baseline_params\n",
    "optimized_hp = best_params\n",
    "\n",
    "# Prepare comparison data\n",
    "comparison_metrics = {\n",
    "    'CNN Kernels L1': (baseline_hp['cnn_kernels_1'], optimized_hp['cnn_kernels_1']),\n",
    "    'CNN Kernels L2': (baseline_hp['cnn_kernels_2'], optimized_hp['cnn_kernels_2']),\n",
    "    'CNN Kernel Size L1': (baseline_hp['cnn_kernel_size_1'], optimized_hp['cnn_kernel_size_1']),\n",
    "    'CNN Kernel Size L2': (baseline_hp['cnn_kernel_size_2'], optimized_hp.get('cnn_kernel_size_2', 3)),\n",
    "    'CNN Dense': (baseline_hp['cnn_dense'], optimized_hp['cnn_dense']),\n",
    "    'CNN Dropout': (baseline_hp['cnn_dropout'], optimized_hp['cnn_dropout']),\n",
    "    'LSTM Hidden': (baseline_hp['lstm_hidden_size'], optimized_hp['lstm_hidden_size']),\n",
    "    'LSTM Layers': (baseline_hp['lstm_layers'], optimized_hp['lstm_layers']),\n",
    "    'LSTM Dense': (baseline_hp['lstm_dense'], optimized_hp['lstm_dense']),\n",
    "    'Batch Size': (baseline_hp['batch_size'], optimized_hp['batch_size']),\n",
    "}\n",
    "\n",
    "# Plot 1: Hyperparameter Comparison (Bar Chart)\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "metrics = list(comparison_metrics.keys())\n",
    "baseline_vals = [comparison_metrics[m][0] for m in metrics]\n",
    "optimized_vals = [comparison_metrics[m][1] for m in metrics]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.barh(x - width/2, baseline_vals, width, label='Baseline', alpha=0.8, color='steelblue')\n",
    "bars2 = ax1.barh(x + width/2, optimized_vals, width, label='Optimized', alpha=0.8, color='coral')\n",
    "\n",
    "ax1.set_xlabel('Parameter Value', fontsize=11, fontweight='bold')\n",
    "ax1.set_ylabel('Hyperparameter', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Hyperparameter Comparison', fontsize=13, fontweight='bold')\n",
    "ax1.set_yticks(x)\n",
    "ax1.set_yticklabels(metrics, fontsize=9)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Plot 2: Total Parameters Comparison\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "models = ['Baseline', 'Optimized']\n",
    "total_params = [\n",
    "    baseline_df['total_params'].sum(),\n",
    "    optimized_df['total_params'].sum()\n",
    "]\n",
    "\n",
    "bars = ax2.bar(models, total_params, color=['steelblue', 'coral'], alpha=0.8, edgecolor='black', linewidth=2)\n",
    "ax2.set_ylabel('Number of Parameters', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Total Model Parameters', fontsize=13, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height):,}',\n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Plot 3: Layer-wise Parameter Distribution\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "\n",
    "# Group parameters by layer type\n",
    "def group_by_type(df):\n",
    "    type_params = {}\n",
    "    for _, row in df.iterrows():\n",
    "        layer_type = row['type']\n",
    "        if layer_type not in type_params:\n",
    "            type_params[layer_type] = 0\n",
    "        type_params[layer_type] += row['total_params']\n",
    "    return type_params\n",
    "\n",
    "baseline_type_params = group_by_type(baseline_df)\n",
    "optimized_type_params = group_by_type(optimized_df)\n",
    "\n",
    "# Get all unique layer types\n",
    "all_types = sorted(set(list(baseline_type_params.keys()) + list(optimized_type_params.keys())))\n",
    "\n",
    "baseline_by_type = [baseline_type_params.get(t, 0) for t in all_types]\n",
    "optimized_by_type = [optimized_type_params.get(t, 0) for t in all_types]\n",
    "\n",
    "x_types = np.arange(len(all_types))\n",
    "width = 0.35\n",
    "\n",
    "ax3.bar(x_types - width/2, baseline_by_type, width, label='Baseline', alpha=0.8, color='steelblue')\n",
    "ax3.bar(x_types + width/2, optimized_by_type, width, label='Optimized', alpha=0.8, color='coral')\n",
    "\n",
    "ax3.set_xlabel('Layer Type', fontsize=11, fontweight='bold')\n",
    "ax3.set_ylabel('Parameters', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('Parameters by Layer Type', fontsize=13, fontweight='bold')\n",
    "ax3.set_xticks(x_types)\n",
    "ax3.set_xticklabels(all_types, rotation=45, ha='right', fontsize=9)\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: Learning Rate and Optimizer\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "ax4.axis('off')\n",
    "\n",
    "comparison_text = f\"\"\"\n",
    "TRAINING CONFIGURATION COMPARISON\n",
    "\n",
    "Baseline (Unoptimized):\n",
    "  • Optimizer: {baseline_hp['optimizer'].upper()}\n",
    "  • Learning Rate: {baseline_hp['learning_rate']:.2e}\n",
    "  • Batch Size: {baseline_hp['batch_size']}\n",
    "  • Total Parameters: {baseline_df['total_params'].sum():,}\n",
    "\n",
    "Optimized:\n",
    "  • Optimizer: {optimized_hp['optimizer'].upper()}\n",
    "  • Learning Rate: {optimized_hp['learning_rate']:.2e}\n",
    "  • Batch Size: {optimized_hp['batch_size']}\n",
    "  • Total Parameters: {optimized_df['total_params'].sum():,}\n",
    "\n",
    "Parameter Reduction/Increase:\n",
    "  • Difference: {optimized_df['total_params'].sum() - baseline_df['total_params'].sum():+,}\n",
    "  • Ratio: {optimized_df['total_params'].sum() / baseline_df['total_params'].sum():.2f}x\n",
    "\"\"\"\n",
    "\n",
    "ax4.text(0.1, 0.9, comparison_text, transform=ax4.transAxes,\n",
    "         fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "# Plot 5: Architectural Differences Summary\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "ax5.axis('off')\n",
    "\n",
    "diff_text = \"KEY ARCHITECTURAL DIFFERENCES:\\n\\n\"\n",
    "for metric, (base_val, opt_val) in comparison_metrics.items():\n",
    "    if base_val != opt_val:\n",
    "        change = opt_val - base_val\n",
    "        pct_change = ((opt_val - base_val) / base_val * 100) if base_val != 0 else 0\n",
    "        diff_text += f\"• {metric}:\\n\"\n",
    "        diff_text += f\"  {base_val} → {opt_val} ({change:+.1f}, {pct_change:+.1f}%)\\n\\n\"\n",
    "\n",
    "if diff_text == \"KEY ARCHITECTURAL DIFFERENCES:\\n\\n\":\n",
    "    diff_text += \"No architectural differences found.\\nBoth models use identical structures.\"\n",
    "\n",
    "ax5.text(0.05, 0.95, diff_text, transform=ax5.transAxes,\n",
    "         fontsize=9, verticalalignment='top', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n",
    "\n",
    "# Plot 6: Performance Comparison\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "\n",
    "metrics_names = ['Test Accuracy', 'Best Val Acc', 'Best Val Loss']\n",
    "baseline_metrics = [\n",
    "    baseline_results['test_accuracy'],\n",
    "    baseline_results['best_val_accuracy'],\n",
    "    baseline_results['best_val_loss']\n",
    "]\n",
    "optimized_metrics = [\n",
    "    acc,  # test accuracy from optimized model\n",
    "    max(history['val_accs']),\n",
    "    min(history['val_losses'])\n",
    "]\n",
    "\n",
    "x_perf = np.arange(len(metrics_names))\n",
    "width = 0.35\n",
    "\n",
    "# Normalize for visualization (loss is inverted)\n",
    "baseline_display = baseline_metrics.copy()\n",
    "optimized_display = optimized_metrics.copy()\n",
    "baseline_display[2] = 1 - baseline_display[2]  # Invert loss for display\n",
    "optimized_display[2] = 1 - optimized_display[2]\n",
    "\n",
    "bars1 = ax6.bar(x_perf - width/2, baseline_display, width, label='Baseline', alpha=0.8, color='steelblue')\n",
    "bars2 = ax6.bar(x_perf + width/2, optimized_display, width, label='Optimized', alpha=0.8, color='coral')\n",
    "\n",
    "ax6.set_ylabel('Score', fontsize=11, fontweight='bold')\n",
    "ax6.set_title('Performance Comparison', fontsize=13, fontweight='bold')\n",
    "ax6.set_xticks(x_perf)\n",
    "ax6.set_xticklabels(metrics_names, fontsize=9)\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2]:\n",
    "    for i, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        actual_val = baseline_metrics[i] if bars == bars1 else optimized_metrics[i]\n",
    "        ax6.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{actual_val:.4f}',\n",
    "                ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.suptitle('Comprehensive Architecture & Performance Comparison', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Visual comparison complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b769985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Report: Architecture Analysis\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ARCHITECTURE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. COMPUTATIONAL GRAPH VISUALIZATIONS:\")\n",
    "print(\"   ✓ Baseline model graph: baseline_model_graph.png\")\n",
    "print(\"   ✓ Optimized model graph: optimized_model_graph.png\")\n",
    "print(\"   → Compare data flow, operation sequences, and layer connections\")\n",
    "\n",
    "print(\"\\n2. STRUCTURAL DIFFERENCES:\")\n",
    "baseline_total = baseline_df['total_params'].sum()\n",
    "optimized_total = optimized_df['total_params'].sum()\n",
    "param_diff = optimized_total - baseline_total\n",
    "param_ratio = optimized_total / baseline_total\n",
    "\n",
    "print(f\"   • Baseline Model: {baseline_total:,} parameters\")\n",
    "print(f\"   • Optimized Model: {optimized_total:,} parameters\")\n",
    "print(f\"   • Difference: {param_diff:+,} ({(param_ratio-1)*100:+.2f}%)\")\n",
    "\n",
    "print(\"\\n3. LAYER COMPOSITION:\")\n",
    "print(f\"   Baseline: {len(baseline_df)} layers\")\n",
    "print(f\"   Optimized: {len(optimized_df)} layers\")\n",
    "\n",
    "print(\"\\n4. OPTIMIZATION IMPACT:\")\n",
    "perf_improvement = (acc - baseline_results['test_accuracy']) * 100\n",
    "print(f\"   • Test Accuracy Improvement: {perf_improvement:+.2f}%\")\n",
    "print(f\"   • Baseline: {baseline_results['test_accuracy']:.4f}\")\n",
    "print(f\"   • Optimized: {acc:.4f}\")\n",
    "\n",
    "print(\"\\n5. KEY ARCHITECTURAL CHANGES:\")\n",
    "for metric, (base_val, opt_val) in comparison_metrics.items():\n",
    "    if base_val != opt_val:\n",
    "        print(f\"   • {metric}: {base_val} → {opt_val}\")\n",
    "\n",
    "print(\"\\n6. TRAINING EFFICIENCY:\")\n",
    "print(f\"   • Baseline epochs: {baseline_results['epochs_trained']}\")\n",
    "print(f\"   • Optimized epochs: {len(history['train_losses'])}\")\n",
    "print(f\"   • Baseline optimizer: {baseline_hp['optimizer']}\")\n",
    "print(f\"   • Optimized optimizer: {optimized_hp['optimizer']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ Complete architecture analysis finished!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b6caf7",
   "metadata": {},
   "source": [
    "#### **Model Internals Visualization: Feature Maps & Hidden States**\n",
    "\n",
    "Deep dive into learned representations to understand model behavior:\n",
    "\n",
    "---\n",
    "\n",
    "### **Visualization Goals**\n",
    "\n",
    "Compare internal representations between baseline (unoptimized) and optimized models:\n",
    "\n",
    "1. **CNN Feature Maps**: Visualize learned spatial-temporal patterns at each convolutional layer\n",
    "2. **LSTM Hidden States**: Track temporal evolution of hidden state activations across sequence\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Visualize Internal Representations?**\n",
    "\n",
    "**CNN Feature Maps:**\n",
    "- Reveal what spatial-temporal patterns the model has learned to detect\n",
    "- Show differences in feature complexity between layers\n",
    "- Compare feature learning effectiveness between optimized vs unoptimized models\n",
    "- Identify if optimization leads to more discriminative features\n",
    "\n",
    "**LSTM Hidden States:**\n",
    "- Understand temporal pattern evolution across the EEG sequence\n",
    "- Visualize how the model tracks information over time\n",
    "- Compare temporal modeling between baseline and optimized architectures\n",
    "- Identify key timesteps where classification decisions are made\n",
    "\n",
    "---\n",
    "\n",
    "### **Interpretation Guide**\n",
    "\n",
    "**Feature Map Patterns:**\n",
    "- Bright/dark regions indicate strong activations (detected patterns)\n",
    "- Layer 1: Low-level features (edges, simple patterns)\n",
    "- Layer 2: Higher-level features (complex spatial-temporal combinations)\n",
    "- Optimized models should show clearer, more structured patterns\n",
    "\n",
    "**Hidden State Dynamics:**\n",
    "- Each row represents one LSTM layer's hidden state\n",
    "- Color intensity shows activation magnitude\n",
    "- Temporal evolution (left to right) shows information flow\n",
    "- Final states (rightmost) influence classification decision\n",
    "\n",
    "---\n",
    "\n",
    "### **Sample Selection**\n",
    "\n",
    "For visualization, we'll use:\n",
    "- Representative samples from each ADHD class\n",
    "- Focus on correctly classified examples to understand successful pattern detection\n",
    "- Compare activations between baseline and optimized models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1c91db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper class to capture intermediate activations\n",
    "class FeatureExtractor:\n",
    "    \"\"\"Extract CNN feature maps and LSTM hidden states during forward pass.\"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.cnn_features = {}\n",
    "        self.lstm_states = None\n",
    "        self.hooks = []\n",
    "        self._register_hooks()\n",
    "    \n",
    "    def _register_hooks(self):\n",
    "        \"\"\"Register forward hooks to capture activations.\"\"\"\n",
    "        \n",
    "        # Hook for first conv layer\n",
    "        def hook_conv1(module, input, output):\n",
    "            self.cnn_features['conv1'] = output.detach()\n",
    "        \n",
    "        # Hook for second conv layer\n",
    "        def hook_conv2(module, input, output):\n",
    "            self.cnn_features['conv2'] = output.detach()\n",
    "        \n",
    "        # Hook for LSTM\n",
    "        def hook_lstm(module, input, output):\n",
    "            # output is (lstm_out, (h_n, c_n))\n",
    "            lstm_out, (h_n, c_n) = output\n",
    "            self.lstm_states = {\n",
    "                'output': lstm_out.detach(),  # [B, seq_len, hidden_size]\n",
    "                'hidden': h_n.detach(),       # [num_layers, B, hidden_size]\n",
    "                'cell': c_n.detach()          # [num_layers, B, hidden_size]\n",
    "            }\n",
    "        \n",
    "        # Register hooks\n",
    "        self.hooks.append(self.model.conv1.register_forward_hook(hook_conv1))\n",
    "        self.hooks.append(self.model.conv2.register_forward_hook(hook_conv2))\n",
    "        self.hooks.append(self.model.lstm.register_forward_hook(hook_lstm))\n",
    "    \n",
    "    def extract(self, x_eeg, x_band):\n",
    "        \"\"\"Forward pass and return features.\"\"\"\n",
    "        self.cnn_features = {}\n",
    "        self.lstm_states = None\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = self.model(x_eeg, x_band)\n",
    "        \n",
    "        return output, self.cnn_features, self.lstm_states\n",
    "    \n",
    "    def remove_hooks(self):\n",
    "        \"\"\"Clean up hooks.\"\"\"\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "\n",
    "print(\"✓ FeatureExtractor class defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f36f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select sample for visualization\n",
    "print(\"Selecting representative samples from test set...\")\n",
    "\n",
    "# Get one sample from each class\n",
    "baseline_model.eval()\n",
    "model.eval()\n",
    "\n",
    "sample_indices = {}\n",
    "with torch.no_grad():\n",
    "    for idx, (xb_eeg, xb_band, yb) in enumerate(baseline_test_loader):\n",
    "        for i in range(len(yb)):\n",
    "            label = int(yb[i].item())\n",
    "            if label not in sample_indices:\n",
    "                sample_indices[label] = {\n",
    "                    'x_eeg': xb_eeg[i:i+1].to(device),\n",
    "                    'x_band': xb_band[i:i+1].to(device),\n",
    "                    'label': label\n",
    "                }\n",
    "            if len(sample_indices) == 4:  # Assuming 4 classes\n",
    "                break\n",
    "        if len(sample_indices) == 4:\n",
    "            break\n",
    "\n",
    "print(f\"✓ Selected {len(sample_indices)} samples (one per class)\")\n",
    "print(f\"Classes represented: {list(sample_indices.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05bd057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from both models for visualization\n",
    "print(\"\\nExtracting CNN feature maps and LSTM hidden states...\")\n",
    "\n",
    "# Choose one sample for detailed visualization (class 0)\n",
    "sample = sample_indices[0]\n",
    "x_eeg_sample = sample['x_eeg']\n",
    "x_band_sample = sample['x_band']\n",
    "\n",
    "# Extract from baseline model\n",
    "baseline_extractor = FeatureExtractor(baseline_model)\n",
    "baseline_output, baseline_cnn_feats, baseline_lstm_states = baseline_extractor.extract(x_eeg_sample, x_band_sample)\n",
    "\n",
    "# Extract from optimized model\n",
    "optimized_extractor = FeatureExtractor(model)\n",
    "optimized_output, optimized_cnn_feats, optimized_lstm_states = optimized_extractor.extract(x_eeg_sample, x_band_sample)\n",
    "\n",
    "print(\"✓ Feature extraction complete\")\n",
    "print(f\"\\nBaseline Model:\")\n",
    "print(f\"  Conv1 output shape: {baseline_cnn_feats['conv1'].shape}\")\n",
    "print(f\"  Conv2 output shape: {baseline_cnn_feats['conv2'].shape}\")\n",
    "print(f\"  LSTM output shape: {baseline_lstm_states['output'].shape}\")\n",
    "print(f\"  LSTM hidden states: {baseline_lstm_states['hidden'].shape}\")\n",
    "\n",
    "print(f\"\\nOptimized Model:\")\n",
    "print(f\"  Conv1 output shape: {optimized_cnn_feats['conv1'].shape}\")\n",
    "print(f\"  Conv2 output shape: {optimized_cnn_feats['conv2'].shape}\")\n",
    "print(f\"  LSTM output shape: {optimized_lstm_states['output'].shape}\")\n",
    "print(f\"  LSTM hidden states: {optimized_lstm_states['hidden'].shape}\")\n",
    "\n",
    "# Predictions\n",
    "baseline_pred = baseline_output.argmax(1).item()\n",
    "optimized_pred = optimized_output.argmax(1).item()\n",
    "true_label = sample['label']\n",
    "\n",
    "print(f\"\\nPredictions for sample (True label: {true_label}):\")\n",
    "print(f\"  Baseline: {baseline_pred}\")\n",
    "print(f\"  Optimized: {optimized_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258c4b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CNN Feature Maps - Comparison\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_cnn_features(baseline_feats, optimized_feats, num_filters=8):\n",
    "    \"\"\"Visualize and compare CNN feature maps from both models.\"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    # Baseline Conv1\n",
    "    conv1_baseline = baseline_feats['conv1'][0].cpu().numpy()  # [C, H, W]\n",
    "    num_show = min(num_filters, conv1_baseline.shape[0])\n",
    "    \n",
    "    for i in range(num_show):\n",
    "        ax = plt.subplot(4, num_show, i + 1)\n",
    "        im = ax.imshow(conv1_baseline[i], cmap='viridis', aspect='auto')\n",
    "        ax.set_title(f'Filter {i+1}', fontsize=10, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Baseline\\nConv1', fontsize=11, fontweight='bold', rotation=0, \n",
    "                         labelpad=40, va='center')\n",
    "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Optimized Conv1\n",
    "    conv1_optimized = optimized_feats['conv1'][0].cpu().numpy()\n",
    "    num_show_opt = min(num_filters, conv1_optimized.shape[0])\n",
    "    \n",
    "    for i in range(num_show_opt):\n",
    "        ax = plt.subplot(4, num_show, num_show + i + 1)\n",
    "        im = ax.imshow(conv1_optimized[i], cmap='viridis', aspect='auto')\n",
    "        ax.set_title(f'Filter {i+1}', fontsize=10, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Optimized\\nConv1', fontsize=11, fontweight='bold', rotation=0, \n",
    "                         labelpad=40, va='center')\n",
    "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Baseline Conv2\n",
    "    conv2_baseline = baseline_feats['conv2'][0].cpu().numpy()\n",
    "    num_show = min(num_filters, conv2_baseline.shape[0])\n",
    "    \n",
    "    for i in range(num_show):\n",
    "        ax = plt.subplot(4, num_show, 2*num_show + i + 1)\n",
    "        im = ax.imshow(conv2_baseline[i], cmap='plasma', aspect='auto')\n",
    "        ax.set_title(f'Filter {i+1}', fontsize=10, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Baseline\\nConv2', fontsize=11, fontweight='bold', rotation=0, \n",
    "                         labelpad=40, va='center')\n",
    "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Optimized Conv2\n",
    "    conv2_optimized = optimized_feats['conv2'][0].cpu().numpy()\n",
    "    num_show_opt = min(num_filters, conv2_optimized.shape[0])\n",
    "    \n",
    "    for i in range(num_show_opt):\n",
    "        ax = plt.subplot(4, num_show, 3*num_show + i + 1)\n",
    "        im = ax.imshow(conv2_optimized[i], cmap='plasma', aspect='auto')\n",
    "        ax.set_title(f'Filter {i+1}', fontsize=10, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Optimized\\nConv2', fontsize=11, fontweight='bold', rotation=0, \n",
    "                         labelpad=40, va='center')\n",
    "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.suptitle('CNN Feature Maps Comparison: Baseline vs Optimized', \n",
    "                 fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualizing CNN feature maps...\")\n",
    "visualize_cnn_features(baseline_cnn_feats, optimized_cnn_feats, num_filters=8)\n",
    "print(\"✓ CNN feature maps visualization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debe4af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize LSTM Hidden State Activations Over Time\n",
    "def visualize_lstm_states(baseline_states, optimized_states):\n",
    "    \"\"\"Visualize and compare LSTM hidden state evolution over time.\"\"\"\n",
    "    \n",
    "    # Extract hidden states [num_layers, batch, hidden_size]\n",
    "    # We'll visualize the evolution of LSTM output over sequence [batch, seq_len, hidden_size]\n",
    "    baseline_lstm_out = baseline_states['output'][0].cpu().numpy()  # [seq_len, hidden_size]\n",
    "    optimized_lstm_out = optimized_states['output'][0].cpu().numpy()\n",
    "    \n",
    "    # Also get final hidden states for each layer\n",
    "    baseline_hidden = baseline_states['hidden'][:, 0, :].cpu().numpy()  # [num_layers, hidden_size]\n",
    "    optimized_hidden = optimized_states['hidden'][:, 0, :].cpu().numpy()\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    \n",
    "    # Plot 1: Baseline LSTM output evolution over time\n",
    "    ax1 = plt.subplot(3, 2, 1)\n",
    "    im1 = ax1.imshow(baseline_lstm_out.T, cmap='RdBu_r', aspect='auto', interpolation='nearest')\n",
    "    ax1.set_xlabel('Time Step', fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel('Hidden Unit', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Baseline: LSTM Output Over Time', fontsize=14, fontweight='bold')\n",
    "    plt.colorbar(im1, ax=ax1, label='Activation')\n",
    "    \n",
    "    # Plot 2: Optimized LSTM output evolution over time\n",
    "    ax2 = plt.subplot(3, 2, 2)\n",
    "    im2 = ax2.imshow(optimized_lstm_out.T, cmap='RdBu_r', aspect='auto', interpolation='nearest')\n",
    "    ax2.set_xlabel('Time Step', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Hidden Unit', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Optimized: LSTM Output Over Time', fontsize=14, fontweight='bold')\n",
    "    plt.colorbar(im2, ax=ax2, label='Activation')\n",
    "    \n",
    "    # Plot 3: Baseline layer-wise final hidden states\n",
    "    ax3 = plt.subplot(3, 2, 3)\n",
    "    im3 = ax3.imshow(baseline_hidden, cmap='viridis', aspect='auto', interpolation='nearest')\n",
    "    ax3.set_xlabel('Hidden Unit', fontsize=12, fontweight='bold')\n",
    "    ax3.set_ylabel('LSTM Layer', fontsize=12, fontweight='bold')\n",
    "    ax3.set_title('Baseline: Final Hidden States (All Layers)', fontsize=14, fontweight='bold')\n",
    "    ax3.set_yticks(range(baseline_hidden.shape[0]))\n",
    "    ax3.set_yticklabels([f'Layer {i+1}' for i in range(baseline_hidden.shape[0])])\n",
    "    plt.colorbar(im3, ax=ax3, label='Activation')\n",
    "    \n",
    "    # Plot 4: Optimized layer-wise final hidden states\n",
    "    ax4 = plt.subplot(3, 2, 4)\n",
    "    im4 = ax4.imshow(optimized_hidden, cmap='viridis', aspect='auto', interpolation='nearest')\n",
    "    ax4.set_xlabel('Hidden Unit', fontsize=12, fontweight='bold')\n",
    "    ax4.set_ylabel('LSTM Layer', fontsize=12, fontweight='bold')\n",
    "    ax4.set_title('Optimized: Final Hidden States (All Layers)', fontsize=14, fontweight='bold')\n",
    "    ax4.set_yticks(range(optimized_hidden.shape[0]))\n",
    "    ax4.set_yticklabels([f'Layer {i+1}' for i in range(optimized_hidden.shape[0])])\n",
    "    plt.colorbar(im4, ax=ax4, label='Activation')\n",
    "    \n",
    "    # Plot 5: Temporal activation statistics (baseline)\n",
    "    ax5 = plt.subplot(3, 2, 5)\n",
    "    timesteps = np.arange(baseline_lstm_out.shape[0])\n",
    "    mean_activation = np.mean(np.abs(baseline_lstm_out), axis=1)\n",
    "    std_activation = np.std(baseline_lstm_out, axis=1)\n",
    "    ax5.plot(timesteps, mean_activation, 'b-', linewidth=2, label='Mean |Activation|')\n",
    "    ax5.fill_between(timesteps, mean_activation - std_activation, \n",
    "                     mean_activation + std_activation, alpha=0.3, color='blue', label='±1 Std Dev')\n",
    "    ax5.set_xlabel('Time Step', fontsize=12, fontweight='bold')\n",
    "    ax5.set_ylabel('Activation Magnitude', fontsize=12, fontweight='bold')\n",
    "    ax5.set_title('Baseline: Temporal Activation Statistics', fontsize=14, fontweight='bold')\n",
    "    ax5.legend()\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 6: Temporal activation statistics (optimized)\n",
    "    ax6 = plt.subplot(3, 2, 6)\n",
    "    timesteps_opt = np.arange(optimized_lstm_out.shape[0])\n",
    "    mean_activation_opt = np.mean(np.abs(optimized_lstm_out), axis=1)\n",
    "    std_activation_opt = np.std(optimized_lstm_out, axis=1)\n",
    "    ax6.plot(timesteps_opt, mean_activation_opt, 'r-', linewidth=2, label='Mean |Activation|')\n",
    "    ax6.fill_between(timesteps_opt, mean_activation_opt - std_activation_opt, \n",
    "                     mean_activation_opt + std_activation_opt, alpha=0.3, color='red', label='±1 Std Dev')\n",
    "    ax6.set_xlabel('Time Step', fontsize=12, fontweight='bold')\n",
    "    ax6.set_ylabel('Activation Magnitude', fontsize=12, fontweight='bold')\n",
    "    ax6.set_title('Optimized: Temporal Activation Statistics', fontsize=14, fontweight='bold')\n",
    "    ax6.legend()\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('LSTM Hidden State Activations: Baseline vs Optimized', \n",
    "                 fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LSTM ACTIVATION STATISTICS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nBaseline Model:\")\n",
    "    print(f\"  LSTM Layers: {baseline_hidden.shape[0]}\")\n",
    "    print(f\"  Hidden Size: {baseline_hidden.shape[1]}\")\n",
    "    print(f\"  Sequence Length: {baseline_lstm_out.shape[0]}\")\n",
    "    print(f\"  Mean Activation: {np.mean(np.abs(baseline_lstm_out)):.4f}\")\n",
    "    print(f\"  Std Activation: {np.std(baseline_lstm_out):.4f}\")\n",
    "    \n",
    "    print(f\"\\nOptimized Model:\")\n",
    "    print(f\"  LSTM Layers: {optimized_hidden.shape[0]}\")\n",
    "    print(f\"  Hidden Size: {optimized_hidden.shape[1]}\")\n",
    "    print(f\"  Sequence Length: {optimized_lstm_out.shape[0]}\")\n",
    "    print(f\"  Mean Activation: {np.mean(np.abs(optimized_lstm_out)):.4f}\")\n",
    "    print(f\"  Std Activation: {np.std(optimized_lstm_out):.4f}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "print(\"\\nVisualizing LSTM hidden state activations...\")\n",
    "visualize_lstm_states(baseline_lstm_states, optimized_lstm_states)\n",
    "print(\"✓ LSTM hidden state visualization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd26b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative Analysis: Feature Activation Patterns\n",
    "def comparative_analysis(baseline_cnn, optimized_cnn, baseline_lstm, optimized_lstm):\n",
    "    \"\"\"Quantitative comparison of learned representations.\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    \n",
    "    # Extract data\n",
    "    baseline_conv1 = baseline_cnn['conv1'][0].cpu().numpy()\n",
    "    optimized_conv1 = optimized_cnn['conv1'][0].cpu().numpy()\n",
    "    baseline_conv2 = baseline_cnn['conv2'][0].cpu().numpy()\n",
    "    optimized_conv2 = optimized_cnn['conv2'][0].cpu().numpy()\n",
    "    \n",
    "    # Plot 1: Filter activation magnitude comparison (Conv1)\n",
    "    ax1 = axes[0, 0]\n",
    "    baseline_conv1_mag = np.mean(np.abs(baseline_conv1), axis=(1, 2))\n",
    "    optimized_conv1_mag = np.mean(np.abs(optimized_conv1), axis=(1, 2))\n",
    "    \n",
    "    x = np.arange(len(baseline_conv1_mag))\n",
    "    width = 0.35\n",
    "    ax1.bar(x - width/2, baseline_conv1_mag, width, label='Baseline', alpha=0.8, color='steelblue')\n",
    "    ax1.bar(x + width/2, optimized_conv1_mag[:len(x)], width, label='Optimized', alpha=0.8, color='coral')\n",
    "    ax1.set_xlabel('Filter Index', fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel('Mean Absolute Activation', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Conv1: Filter Activation Magnitudes', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 2: Filter activation magnitude comparison (Conv2)\n",
    "    ax2 = axes[0, 1]\n",
    "    baseline_conv2_mag = np.mean(np.abs(baseline_conv2), axis=(1, 2))\n",
    "    optimized_conv2_mag = np.mean(np.abs(optimized_conv2), axis=(1, 2))\n",
    "    \n",
    "    x2 = np.arange(len(baseline_conv2_mag))\n",
    "    ax2.bar(x2 - width/2, baseline_conv2_mag, width, label='Baseline', alpha=0.8, color='steelblue')\n",
    "    ax2.bar(x2 + width/2, optimized_conv2_mag[:len(x2)], width, label='Optimized', alpha=0.8, color='coral')\n",
    "    ax2.set_xlabel('Filter Index', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Mean Absolute Activation', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Conv2: Filter Activation Magnitudes', fontsize=14, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 3: LSTM activation distribution\n",
    "    ax3 = axes[1, 0]\n",
    "    baseline_lstm_out = baseline_lstm['output'][0].cpu().numpy().flatten()\n",
    "    optimized_lstm_out = optimized_lstm['output'][0].cpu().numpy().flatten()\n",
    "    \n",
    "    ax3.hist(baseline_lstm_out, bins=50, alpha=0.6, label='Baseline', color='steelblue', density=True)\n",
    "    ax3.hist(optimized_lstm_out, bins=50, alpha=0.6, label='Optimized', color='coral', density=True)\n",
    "    ax3.set_xlabel('Activation Value', fontsize=12, fontweight='bold')\n",
    "    ax3.set_ylabel('Density', fontsize=12, fontweight='bold')\n",
    "    ax3.set_title('LSTM: Activation Distribution', fontsize=14, fontweight='bold')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 4: Activation sparsity (percentage of near-zero activations)\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    def compute_sparsity(features_dict, threshold=0.1):\n",
    "        \"\"\"Compute percentage of activations below threshold.\"\"\"\n",
    "        sparsity = {}\n",
    "        for key, val in features_dict.items():\n",
    "            if 'conv' in key:\n",
    "                data = val[0].cpu().numpy().flatten()\n",
    "                sparsity[key] = (np.abs(data) < threshold).sum() / len(data) * 100\n",
    "        return sparsity\n",
    "    \n",
    "    baseline_sparsity = compute_sparsity(baseline_cnn)\n",
    "    optimized_sparsity = compute_sparsity(optimized_cnn)\n",
    "    \n",
    "    layers = list(baseline_sparsity.keys())\n",
    "    baseline_vals = [baseline_sparsity[k] for k in layers]\n",
    "    optimized_vals = [optimized_sparsity[k] for k in layers]\n",
    "    \n",
    "    x4 = np.arange(len(layers))\n",
    "    ax4.bar(x4 - width/2, baseline_vals, width, label='Baseline', alpha=0.8, color='steelblue')\n",
    "    ax4.bar(x4 + width/2, optimized_vals, width, label='Optimized', alpha=0.8, color='coral')\n",
    "    ax4.set_xlabel('Layer', fontsize=12, fontweight='bold')\n",
    "    ax4.set_ylabel('Sparsity (%)', fontsize=12, fontweight='bold')\n",
    "    ax4.set_title('CNN: Activation Sparsity (|activation| < 0.1)', fontsize=14, fontweight='bold')\n",
    "    ax4.set_xticks(x4)\n",
    "    ax4.set_xticklabels(layers)\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.suptitle('Comparative Analysis: Feature Activation Patterns', \n",
    "                 fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"COMPARATIVE FEATURE ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\nCNN Feature Statistics:\")\n",
    "    print(f\"  Baseline Conv1 - Mean: {np.mean(baseline_conv1_mag):.4f}, Std: {np.std(baseline_conv1_mag):.4f}\")\n",
    "    print(f\"  Optimized Conv1 - Mean: {np.mean(optimized_conv1_mag):.4f}, Std: {np.std(optimized_conv1_mag):.4f}\")\n",
    "    print(f\"  Baseline Conv2 - Mean: {np.mean(baseline_conv2_mag):.4f}, Std: {np.std(baseline_conv2_mag):.4f}\")\n",
    "    print(f\"  Optimized Conv2 - Mean: {np.mean(optimized_conv2_mag):.4f}, Std: {np.std(optimized_conv2_mag):.4f}\")\n",
    "    \n",
    "    print(\"\\nLSTM Activation Statistics:\")\n",
    "    print(f\"  Baseline - Mean: {np.mean(baseline_lstm_out):.4f}, Std: {np.std(baseline_lstm_out):.4f}\")\n",
    "    print(f\"  Optimized - Mean: {np.mean(optimized_lstm_out):.4f}, Std: {np.std(optimized_lstm_out):.4f}\")\n",
    "    \n",
    "    print(\"\\nSparsity Analysis:\")\n",
    "    for layer in layers:\n",
    "        print(f\"  {layer} - Baseline: {baseline_sparsity[layer]:.2f}%, Optimized: {optimized_sparsity[layer]:.2f}%\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "\n",
    "print(\"\\nPerforming comparative analysis...\")\n",
    "comparative_analysis(baseline_cnn_feats, optimized_cnn_feats, \n",
    "                    baseline_lstm_states, optimized_lstm_states)\n",
    "print(\"✓ Comparative analysis complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f84c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup: Remove hooks\n",
    "baseline_extractor.remove_hooks()\n",
    "optimized_extractor.remove_hooks()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VISUALIZATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nKey Insights from Internal Representations:\")\n",
    "print(\"\\n1. CNN Feature Maps:\")\n",
    "print(\"   - Conv1: Captures low-level spatial-temporal patterns\")\n",
    "print(\"   - Conv2: Extracts higher-level feature combinations\")\n",
    "print(\"   - Compare activation magnitudes and patterns between models\")\n",
    "print(\"\\n2. LSTM Hidden States:\")\n",
    "print(\"   - Temporal evolution shows information flow across sequence\")\n",
    "print(\"   - Final hidden states encode compressed temporal information\")\n",
    "print(\"   - Layer-wise activations reveal hierarchical temporal processing\")\n",
    "print(\"\\n3. Comparative Analysis:\")\n",
    "print(\"   - Filter activation magnitudes show feature importance\")\n",
    "print(\"   - Activation distributions reveal learning characteristics\")\n",
    "print(\"   - Sparsity indicates selective feature detection\")\n",
    "print(\"\\n4. Optimization Impact:\")\n",
    "print(\"   - Optimized model may show more structured/selective activations\")\n",
    "print(\"   - Better hyperparameters can lead to clearer feature separation\")\n",
    "print(\"   - LSTM architecture changes affect temporal modeling capacity\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n✓ All visualizations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8c0f45",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Training Dynamics & Performance Comparison**\n",
    "\n",
    "Comprehensive side-by-side comparison of training behavior and final performance between baseline (unoptimized) and optimized models:\n",
    "\n",
    "---\n",
    "\n",
    "### **Comparison Goals**\n",
    "\n",
    "**Training Curves Analysis:**\n",
    "- Compare convergence speed and stability\n",
    "- Identify overfitting patterns and generalization gaps\n",
    "- Assess impact of hyperparameter optimization on learning dynamics\n",
    "- Evaluate early stopping effectiveness\n",
    "\n",
    "**Confusion Matrix Analysis:**\n",
    "- Compare classification performance across all classes\n",
    "- Identify class-specific improvements\n",
    "- Understand misclassification patterns\n",
    "- Quantify optimization impact on per-class accuracy\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Metrics to Compare**\n",
    "\n",
    "**Training Dynamics:**\n",
    "- Convergence rate (epochs to best performance)\n",
    "- Training vs validation gap (overfitting measure)\n",
    "- Final training and validation accuracy/loss\n",
    "- Learning curve smoothness and stability\n",
    "\n",
    "**Classification Performance:**\n",
    "- Overall accuracy improvement\n",
    "- Per-class precision, recall, and F1-score\n",
    "- Confusion matrix diagonal strength (correct predictions)\n",
    "- Reduction in misclassifications\n",
    "\n",
    "---\n",
    "\n",
    "### **Interpretation Guide**\n",
    "\n",
    "**Training Curves:**\n",
    "- **Faster convergence** → Better hyperparameters for learning\n",
    "- **Smaller train-val gap** → Better regularization and generalization\n",
    "- **Smoother curves** → More stable training process\n",
    "- **Higher final accuracy** → Better overall optimization\n",
    "\n",
    "**Confusion Matrices:**\n",
    "- **Brighter diagonal** → More correct predictions\n",
    "- **Darker off-diagonal** → Fewer misclassifications\n",
    "- **Class balance** → Even performance across categories\n",
    "- **Comparison highlights** → Classes that benefited most from optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba23d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-Side Training Curves Comparison\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Extract training histories\n",
    "baseline_train_acc = baseline_history['train_accs']\n",
    "baseline_val_acc = baseline_history['val_accs']\n",
    "baseline_train_loss = baseline_history['train_losses']\n",
    "baseline_val_loss = baseline_history['val_losses']\n",
    "\n",
    "optimized_train_acc = history['train_accs']\n",
    "optimized_val_acc = history['val_accs']\n",
    "optimized_train_loss = history['train_losses']\n",
    "optimized_val_loss = history['val_losses']\n",
    "\n",
    "# Create epochs arrays\n",
    "baseline_epochs = np.arange(1, len(baseline_train_acc) + 1)\n",
    "optimized_epochs = np.arange(1, len(optimized_train_acc) + 1)\n",
    "\n",
    "# Plot 1: Baseline Accuracy\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "ax1.plot(baseline_epochs, baseline_train_acc, 'b-', linewidth=2, label='Training', alpha=0.8)\n",
    "ax1.plot(baseline_epochs, baseline_val_acc, 'r-', linewidth=2, label='Validation', alpha=0.8)\n",
    "ax1.axhline(y=max(baseline_val_acc), color='green', linestyle='--', alpha=0.5, \n",
    "            label=f'Best Val: {max(baseline_val_acc):.4f}')\n",
    "ax1.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Baseline: Accuracy Curves', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([0, 1])\n",
    "\n",
    "# Plot 2: Optimized Accuracy\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "ax2.plot(optimized_epochs, optimized_train_acc, 'b-', linewidth=2, label='Training', alpha=0.8)\n",
    "ax2.plot(optimized_epochs, optimized_val_acc, 'r-', linewidth=2, label='Validation', alpha=0.8)\n",
    "ax2.axhline(y=max(optimized_val_acc), color='green', linestyle='--', alpha=0.5,\n",
    "            label=f'Best Val: {max(optimized_val_acc):.4f}')\n",
    "ax2.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Optimized: Accuracy Curves', fontsize=14, fontweight='bold')\n",
    "ax2.legend(loc='lower right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "# Plot 3: Overlay Comparison - Validation Accuracy\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "ax3.plot(baseline_epochs, baseline_val_acc, 'steelblue', linewidth=2.5, \n",
    "         label=f'Baseline (Best: {max(baseline_val_acc):.4f})', alpha=0.8)\n",
    "ax3.plot(optimized_epochs, optimized_val_acc, 'coral', linewidth=2.5,\n",
    "         label=f'Optimized (Best: {max(optimized_val_acc):.4f})', alpha=0.8)\n",
    "ax3.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Validation Accuracy', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Validation Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "ax3.legend(loc='lower right')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_ylim([0, 1])\n",
    "\n",
    "# Plot 4: Baseline Loss\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "ax4.plot(baseline_epochs, baseline_train_loss, 'b-', linewidth=2, label='Training', alpha=0.8)\n",
    "ax4.plot(baseline_epochs, baseline_val_loss, 'r-', linewidth=2, label='Validation', alpha=0.8)\n",
    "ax4.axhline(y=min(baseline_val_loss), color='green', linestyle='--', alpha=0.5,\n",
    "            label=f'Best Val: {min(baseline_val_loss):.4f}')\n",
    "ax4.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Baseline: Loss Curves', fontsize=14, fontweight='bold')\n",
    "ax4.legend(loc='upper right')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Optimized Loss\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "ax5.plot(optimized_epochs, optimized_train_loss, 'b-', linewidth=2, label='Training', alpha=0.8)\n",
    "ax5.plot(optimized_epochs, optimized_val_loss, 'r-', linewidth=2, label='Validation', alpha=0.8)\n",
    "ax5.axhline(y=min(optimized_val_loss), color='green', linestyle='--', alpha=0.5,\n",
    "            label=f'Best Val: {min(optimized_val_loss):.4f}')\n",
    "ax5.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "ax5.set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
    "ax5.set_title('Optimized: Loss Curves', fontsize=14, fontweight='bold')\n",
    "ax5.legend(loc='upper right')\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Overlay Comparison - Validation Loss\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "ax6.plot(baseline_epochs, baseline_val_loss, 'steelblue', linewidth=2.5,\n",
    "         label=f'Baseline (Best: {min(baseline_val_loss):.4f})', alpha=0.8)\n",
    "ax6.plot(optimized_epochs, optimized_val_loss, 'coral', linewidth=2.5,\n",
    "         label=f'Optimized (Best: {min(optimized_val_loss):.4f})', alpha=0.8)\n",
    "ax6.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "ax6.set_ylabel('Validation Loss', fontsize=12, fontweight='bold')\n",
    "ax6.set_title('Validation Loss Comparison', fontsize=14, fontweight='bold')\n",
    "ax6.legend(loc='upper right')\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Training Dynamics: Baseline vs Optimized', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Training curves comparison complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5b3459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrices for both models\n",
    "print(\"Generating confusion matrices for comparison...\")\n",
    "\n",
    "# Baseline model confusion matrix (already computed during baseline evaluation)\n",
    "baseline_cm = conf_matrix  # From baseline evaluation\n",
    "\n",
    "# Optimized model confusion matrix\n",
    "optimized_model = model  # The optimized model\n",
    "optimized_model.eval()\n",
    "\n",
    "all_preds_opt = []\n",
    "all_labels_opt = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb_eeg, xb_band, yb in test_loader:\n",
    "        xb_eeg = xb_eeg.to(device)\n",
    "        xb_band = xb_band.to(device)\n",
    "        preds = optimized_model(xb_eeg, xb_band).argmax(1).cpu().numpy()\n",
    "        all_preds_opt.append(preds)\n",
    "        all_labels_opt.append(yb.numpy())\n",
    "\n",
    "all_preds_opt = np.concatenate(all_preds_opt)\n",
    "all_labels_opt = np.concatenate(all_labels_opt)\n",
    "\n",
    "optimized_cm = confusion_matrix(all_labels_opt, all_preds_opt)\n",
    "optimized_acc = accuracy_score(all_labels_opt, all_preds_opt)\n",
    "\n",
    "print(f\"✓ Baseline Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"✓ Optimized Test Accuracy: {optimized_acc:.4f}\")\n",
    "print(f\"✓ Improvement: {(optimized_acc - test_accuracy):.4f} ({(optimized_acc - test_accuracy)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a66854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-Side Confusion Matrix Comparison\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "\n",
    "# Determine number of classes\n",
    "n_classes = baseline_cm.shape[0]\n",
    "class_labels = [f'Class {i}' for i in range(n_classes)]\n",
    "\n",
    "# Plot 1: Baseline Confusion Matrix\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "sns.heatmap(baseline_cm, annot=True, fmt='d', cmap='Blues', square=True, \n",
    "            cbar_kws={'label': 'Count'}, ax=ax1, \n",
    "            xticklabels=class_labels, yticklabels=class_labels,\n",
    "            linewidths=0.5, linecolor='gray')\n",
    "ax1.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "ax1.set_title(f'Baseline Confusion Matrix\\nAccuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)', \n",
    "              fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 2: Optimized Confusion Matrix\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "sns.heatmap(optimized_cm, annot=True, fmt='d', cmap='Oranges', square=True,\n",
    "            cbar_kws={'label': 'Count'}, ax=ax2,\n",
    "            xticklabels=class_labels, yticklabels=class_labels,\n",
    "            linewidths=0.5, linecolor='gray')\n",
    "ax2.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "ax2.set_title(f'Optimized Confusion Matrix\\nAccuracy: {optimized_acc:.4f} ({optimized_acc*100:.2f}%)', \n",
    "              fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 3: Difference Heatmap (Optimized - Baseline)\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "diff_cm = optimized_cm - baseline_cm\n",
    "\n",
    "# Use diverging colormap centered at 0\n",
    "vmax = max(abs(diff_cm.min()), abs(diff_cm.max()))\n",
    "sns.heatmap(diff_cm, annot=True, fmt='d', cmap='RdBu_r', center=0, \n",
    "            square=True, cbar_kws={'label': 'Difference'},\n",
    "            vmin=-vmax, vmax=vmax, ax=ax3,\n",
    "            xticklabels=class_labels, yticklabels=class_labels,\n",
    "            linewidths=0.5, linecolor='gray')\n",
    "ax3.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "improvement = (optimized_acc - test_accuracy) * 100\n",
    "ax3.set_title(f'Improvement (Optimized - Baseline)\\nΔ Accuracy: {improvement:+.2f}%', \n",
    "              fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Confusion Matrix Comparison: Baseline vs Optimized', \n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Confusion matrix comparison complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc03e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-Class Performance Comparison\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get detailed classification reports\n",
    "baseline_report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "optimized_report = classification_report(all_labels_opt, all_preds_opt, output_dict=True)\n",
    "\n",
    "# Extract per-class metrics\n",
    "classes = sorted([k for k in baseline_report.keys() if k.isdigit()])\n",
    "metrics = ['precision', 'recall', 'f1-score']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    baseline_vals = [baseline_report[c][metric] for c in classes]\n",
    "    optimized_vals = [optimized_report[c][metric] for c in classes]\n",
    "    \n",
    "    x = np.arange(len(classes))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, baseline_vals, width, label='Baseline', \n",
    "                   alpha=0.8, color='steelblue', edgecolor='black', linewidth=1.5)\n",
    "    bars2 = ax.bar(x + width/2, optimized_vals, width, label='Optimized',\n",
    "                   alpha=0.8, color='coral', edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax.set_xlabel('Class', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(metric.replace('-', ' ').title(), fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'Per-Class {metric.replace(\"-\", \" \").title()} Comparison', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f'Class {c}' for c in classes])\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    ax.set_ylim([0, 1])\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.3f}',\n",
    "                   ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.suptitle('Per-Class Performance Metrics: Baseline vs Optimized', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Per-class performance comparison complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b0b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Dynamics Summary Statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING DYNAMICS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"BASELINE MODEL (UNOPTIMIZED)\")\n",
    "print(\"-\"*70)\n",
    "print(f\"Total Epochs Trained: {len(baseline_train_acc)}\")\n",
    "print(f\"\\nTraining Performance:\")\n",
    "print(f\"  Final Training Accuracy: {baseline_train_acc[-1]:.4f}\")\n",
    "print(f\"  Final Training Loss: {baseline_train_loss[-1]:.4f}\")\n",
    "print(f\"\\nValidation Performance:\")\n",
    "print(f\"  Best Validation Accuracy: {max(baseline_val_acc):.4f}\")\n",
    "print(f\"  Best Validation Loss: {min(baseline_val_loss):.4f}\")\n",
    "print(f\"  Final Validation Accuracy: {baseline_val_acc[-1]:.4f}\")\n",
    "print(f\"  Final Validation Loss: {baseline_val_loss[-1]:.4f}\")\n",
    "print(f\"\\nConvergence:\")\n",
    "best_epoch_baseline = np.argmax(baseline_val_acc) + 1\n",
    "print(f\"  Epoch of Best Val Acc: {best_epoch_baseline}\")\n",
    "print(f\"\\nGeneralization Gap:\")\n",
    "gap_baseline = baseline_train_acc[-1] - baseline_val_acc[-1]\n",
    "print(f\"  Train-Val Accuracy Gap: {gap_baseline:.4f}\")\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"  Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"OPTIMIZED MODEL\")\n",
    "print(\"-\"*70)\n",
    "print(f\"Total Epochs Trained: {len(optimized_train_acc)}\")\n",
    "print(f\"\\nTraining Performance:\")\n",
    "print(f\"  Final Training Accuracy: {optimized_train_acc[-1]:.4f}\")\n",
    "print(f\"  Final Training Loss: {optimized_train_loss[-1]:.4f}\")\n",
    "print(f\"\\nValidation Performance:\")\n",
    "print(f\"  Best Validation Accuracy: {max(optimized_val_acc):.4f}\")\n",
    "print(f\"  Best Validation Loss: {min(optimized_val_loss):.4f}\")\n",
    "print(f\"  Final Validation Accuracy: {optimized_val_acc[-1]:.4f}\")\n",
    "print(f\"  Final Validation Loss: {optimized_val_loss[-1]:.4f}\")\n",
    "print(f\"\\nConvergence:\")\n",
    "best_epoch_optimized = np.argmax(optimized_val_acc) + 1\n",
    "print(f\"  Epoch of Best Val Acc: {best_epoch_optimized}\")\n",
    "print(f\"\\nGeneralization Gap:\")\n",
    "gap_optimized = optimized_train_acc[-1] - optimized_val_acc[-1]\n",
    "print(f\"  Train-Val Accuracy Gap: {gap_optimized:.4f}\")\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"  Test Accuracy: {optimized_acc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"IMPROVEMENT ANALYSIS\")\n",
    "print(\"-\"*70)\n",
    "print(f\"\\nAccuracy Improvements:\")\n",
    "print(f\"  Test Accuracy: {test_accuracy:.4f} → {optimized_acc:.4f} ({(optimized_acc-test_accuracy)*100:+.2f}%)\")\n",
    "print(f\"  Best Val Accuracy: {max(baseline_val_acc):.4f} → {max(optimized_val_acc):.4f} ({(max(optimized_val_acc)-max(baseline_val_acc))*100:+.2f}%)\")\n",
    "print(f\"\\nLoss Improvements:\")\n",
    "print(f\"  Best Val Loss: {min(baseline_val_loss):.4f} → {min(optimized_val_loss):.4f} ({(min(optimized_val_loss)-min(baseline_val_loss))*100:+.2f}%)\")\n",
    "print(f\"\\nGeneralization:\")\n",
    "print(f\"  Train-Val Gap: {gap_baseline:.4f} → {gap_optimized:.4f} ({(gap_optimized-gap_baseline)*100:+.2f}%)\")\n",
    "gap_improvement = \"Better\" if gap_optimized < gap_baseline else \"Worse\"\n",
    "print(f\"  Generalization: {gap_improvement}\")\n",
    "print(f\"\\nConvergence Speed:\")\n",
    "print(f\"  Epochs to Best: {best_epoch_baseline} → {best_epoch_optimized} ({best_epoch_optimized-best_epoch_baseline:+d})\")\n",
    "print(f\"  Total Epochs: {len(baseline_train_acc)} → {len(optimized_train_acc)} ({len(optimized_train_acc)-len(baseline_train_acc):+d})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ Training dynamics analysis complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Performance Summary Visualization\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Plot 1: Overall Accuracy Comparison\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "models = ['Baseline', 'Optimized']\n",
    "test_accs = [test_accuracy, optimized_acc]\n",
    "val_accs = [max(baseline_val_acc), max(optimized_val_acc)]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, test_accs, width, label='Test Accuracy', \n",
    "                alpha=0.8, color='steelblue', edgecolor='black', linewidth=2)\n",
    "bars2 = ax1.bar(x + width/2, val_accs, width, label='Best Val Accuracy',\n",
    "                alpha=0.8, color='coral', edgecolor='black', linewidth=2)\n",
    "\n",
    "ax1.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Overall Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(models)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "ax1.set_ylim([0, 1])\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.4f}',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Plot 2: Loss Comparison\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "losses = [min(baseline_val_loss), min(optimized_val_loss)]\n",
    "\n",
    "bars = ax2.bar(models, losses, color=['steelblue', 'coral'], \n",
    "               alpha=0.8, edgecolor='black', linewidth=2)\n",
    "ax2.set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Best Validation Loss Comparison', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.4f}',\n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Plot 3: Convergence Speed\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "convergence = [best_epoch_baseline, best_epoch_optimized]\n",
    "\n",
    "bars = ax3.bar(models, convergence, color=['steelblue', 'coral'],\n",
    "               alpha=0.8, edgecolor='black', linewidth=2)\n",
    "ax3.set_ylabel('Epochs', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Epochs to Best Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}',\n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Plot 4: Train-Val Gap (Generalization)\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "gaps = [gap_baseline, gap_optimized]\n",
    "\n",
    "bars = ax4.bar(models, gaps, color=['steelblue', 'coral'],\n",
    "               alpha=0.8, edgecolor='black', linewidth=2)\n",
    "ax4.set_ylabel('Accuracy Gap', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Train-Val Generalization Gap\\n(Lower is Better)', fontsize=14, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "ax4.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.4f}',\n",
    "            ha='center', va='bottom' if height > 0 else 'top', \n",
    "            fontsize=10, fontweight='bold')\n",
    "\n",
    "# Plot 5: Improvement Metrics\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "improvements = {\n",
    "    'Test Acc': (optimized_acc - test_accuracy) * 100,\n",
    "    'Val Acc': (max(optimized_val_acc) - max(baseline_val_acc)) * 100,\n",
    "    'Val Loss': (min(optimized_val_loss) - min(baseline_val_loss)) * 100,\n",
    "    'Gen Gap': (gap_optimized - gap_baseline) * 100\n",
    "}\n",
    "\n",
    "metric_names = list(improvements.keys())\n",
    "metric_values = list(improvements.values())\n",
    "colors_imp = ['green' if v > 0 else 'red' for v in metric_values[:2]] + \\\n",
    "             ['green' if v < 0 else 'red' for v in metric_values[2:]]\n",
    "\n",
    "bars = ax5.barh(metric_names, metric_values, color=colors_imp, \n",
    "                alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax5.set_xlabel('Improvement (%)', fontsize=12, fontweight='bold')\n",
    "ax5.set_title('Performance Improvements\\n(Optimized - Baseline)', fontsize=14, fontweight='bold')\n",
    "ax5.grid(True, alpha=0.3, axis='x')\n",
    "ax5.axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
    "\n",
    "for i, (bar, val) in enumerate(zip(bars, metric_values)):\n",
    "    ax5.text(val, bar.get_y() + bar.get_height()/2.,\n",
    "            f'{val:+.2f}%',\n",
    "            ha='left' if val > 0 else 'right',\n",
    "            va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Plot 6: Summary Text\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "ax6.axis('off')\n",
    "\n",
    "summary_text = f\"\"\"\n",
    "OPTIMIZATION IMPACT SUMMARY\n",
    "\n",
    "✓ Test Accuracy Improvement:\n",
    "  {test_accuracy:.4f} → {optimized_acc:.4f}\n",
    "  Δ = {(optimized_acc - test_accuracy)*100:+.2f}%\n",
    "\n",
    "✓ Validation Accuracy Improvement:\n",
    "  {max(baseline_val_acc):.4f} → {max(optimized_val_acc):.4f}\n",
    "  Δ = {(max(optimized_val_acc) - max(baseline_val_acc))*100:+.2f}%\n",
    "\n",
    "✓ Loss Reduction:\n",
    "  {min(baseline_val_loss):.4f} → {min(optimized_val_loss):.4f}\n",
    "  Δ = {(min(optimized_val_loss) - min(baseline_val_loss))*100:+.2f}%\n",
    "\n",
    "✓ Convergence Speed:\n",
    "  {best_epoch_baseline} → {best_epoch_optimized} epochs\n",
    "  Δ = {best_epoch_optimized - best_epoch_baseline:+d} epochs\n",
    "\n",
    "✓ Generalization Gap:\n",
    "  {gap_baseline:.4f} → {gap_optimized:.4f}\n",
    "  Δ = {(gap_optimized - gap_baseline)*100:+.2f}%\n",
    "\n",
    "{'✓ Better Generalization' if gap_optimized < gap_baseline else '⚠ Worse Generalization'}\n",
    "{'✓ Faster Convergence' if best_epoch_optimized < best_epoch_baseline else '⚠ Slower Convergence'}\n",
    "{'✓ Improved Performance' if optimized_acc > test_accuracy else '⚠ No Improvement'}\n",
    "\"\"\"\n",
    "\n",
    "ax6.text(0.1, 0.9, summary_text, transform=ax6.transAxes,\n",
    "         fontsize=11, verticalalignment='top', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.3))\n",
    "\n",
    "plt.suptitle('Comprehensive Performance Comparison: Baseline vs Optimized', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Comprehensive performance summary complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4e5135",
   "metadata": {},
   "source": [
    "#### **Cross-Validation Experiments**\n",
    "\n",
    "Comprehensive model evaluation using multiple cross-validation strategies to assess generalization:\n",
    "\n",
    "---\n",
    "\n",
    "### **Experiment 1: K-Fold Window-Based Cross-Validation**\n",
    "\n",
    "**Configuration:**\n",
    "- K=11 folds\n",
    "- Split by temporal window segments (not subjects)\n",
    "- Random shuffle before folding\n",
    "- Uses cyclic iterator for balanced fold distribution\n",
    "\n",
    "**Purpose:**\n",
    "- Assess model generalization to unseen temporal windows\n",
    "- Tests ability to classify different time segments\n",
    "- Faster than subject-based CV\n",
    "- Subject data can appear in both train and test sets\n",
    "\n",
    "**Characteristics:**\n",
    "- May overestimate performance (data leakage from same subject)\n",
    "- Good for assessing temporal pattern learning\n",
    "- Less representative of real-world deployment\n",
    "\n",
    "---\n",
    "\n",
    "### **Experiment 2: Leave-One-Subject-Out Cross-Validation (LOSOCV)**\n",
    "\n",
    "**Configuration:**\n",
    "- Folds equal to number of unique subjects\n",
    "- Each fold: one subject for testing, all others for training\n",
    "- Windows from same subject grouped together\n",
    "- No data leakage between train/test\n",
    "\n",
    "**Purpose:**\n",
    "- **Gold standard** for subject-independent evaluation\n",
    "- Tests true generalization to new, unseen individuals\n",
    "- Most realistic clinical deployment scenario\n",
    "- Accounts for inter-subject variability\n",
    "\n",
    "**Clinical Relevance:**\n",
    "- Simulates real diagnostic workflow\n",
    "- Model must generalize to patients not in training set\n",
    "- Identifies subject-specific overfitting\n",
    "- More conservative performance estimate\n",
    "\n",
    "---\n",
    "\n",
    "### **Evaluation Metrics**\n",
    "\n",
    "Both experiments report:\n",
    "- **Mean accuracy** across all folds\n",
    "- **Standard deviation** (indicates model stability)\n",
    "- **Per-fold accuracy** for detailed analysis\n",
    "\n",
    "**Interpretation:**\n",
    "- Lower std dev = more stable, reliable model\n",
    "- Window-based: baseline generalization capability\n",
    "- Subject-based: clinically relevant performance\n",
    "\n",
    "---\n",
    "\n",
    "### **Trade-offs Summary**\n",
    "\n",
    "| Aspect | Window-Based K-Fold | Leave-One-Subject-Out |\n",
    "|--------|---------------------|------------------------|\n",
    "| **Speed** | Faster | Slower (more folds) |\n",
    "| **Realism** | Less realistic | Highly realistic |\n",
    "| **Performance** | Often higher | More conservative |\n",
    "| **Data Leakage** | Possible | None |\n",
    "| **Clinical Value** | Limited | High |\n",
    "| **Use Case** | Quick validation | Final evaluation |\n",
    "\n",
    "Both approaches validate model robustness from complementary perspectives and help identify different types of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d160b-68be-4b06-976c-97bcbd423f07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# map params to integers where needed\n",
    "params = {'batch_size': 64, 'cnn_dense': 256, 'cnn_dropout': np.float64(0.3571401842400106), 'cnn_kernel_size_1': 5, 'cnn_kernel_size_2': 3, 'cnn_kernels_1': 32, 'cnn_kernels_2': 16, 'learning_rate': np.float64(1.8587640600578385e-05), 'lstm_dense': 64, 'lstm_hidden_size': 96, 'lstm_layers': 2, 'optimizer': 'sgd'}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "unique_subjects = list(df['Window'].unique())\n",
    "accs = []\n",
    "variances = []\n",
    "batch_size = params['batch_size']\n",
    "\n",
    "K_FOLDS = 11\n",
    "fold_size = len(unique_subjects) // K_FOLDS\n",
    "\n",
    "random.shuffle(unique_subjects)\n",
    "\n",
    "cyclic = itertools.cycle(unique_subjects)\n",
    "batched_cyclic = batched(cyclic, n=fold_size)\n",
    "folds = itertools.islice(batched_cyclic, K_FOLDS)\n",
    "    \n",
    "for i, fold in enumerate(folds):\n",
    "    print(f\"Starting fold {i + 1}/{K_FOLDS}\")\n",
    "\n",
    "    train_df = df[~df['Window'].isin(fold)]\n",
    "    test_df   = df[df['Window'].isin(fold)]\n",
    "\n",
    "    train_loader = get_dataset(train_df, batch_size=batch_size)\n",
    "    test_loader  = get_dataset(test_df, batch_size=batch_size)\n",
    "    model, criterion, optimizer = get_model(params)\n",
    "\n",
    "    # Train with modest epochs; early stopping inside fit handles rest\n",
    "    history = model.fit(\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        epochs=100,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        patience=15\n",
    "    )\n",
    "\n",
    "    acc, *_ = get_validation(model, test_loader, device)\n",
    "    accs.append(acc)\n",
    "\n",
    "    print(f\"Fold {i + 1} Accuracy:\", acc)\n",
    "\n",
    "print(f\"k-Fold CV Mean Accuracy: {np.mean(accs):.4f} ± {np.std(accs):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a4bb1-479f-46a1-bd12-50d340d54b0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "params = readable\n",
    "\n",
    "unique_samples = list(df['Window'].unique())\n",
    "subject_count = df['ID'].nunique()\n",
    "accs = []\n",
    "variances = []\n",
    "batch_size = params['batch_size']\n",
    "\n",
    "fold_size = len(unique_samples) // subject_count\n",
    "random.shuffle(unique_samples)\n",
    "\n",
    "cyclic = itertools.cycle(unique_samples)\n",
    "batched_cyclic = batched(cyclic, n=fold_size)\n",
    "folds = itertools.islice(batched_cyclic, subject_count)\n",
    "\n",
    "for i, fold in enumerate(folds):\n",
    "    print(f\"[{get_timestamp()}] Starting fold {i + 1}/{subject_count}\")\n",
    "\n",
    "    train_df = df[~df['Window'].isin(fold)]\n",
    "    test_df   = df[df['Window'].isin(fold)]\n",
    "\n",
    "    train_loader = get_dataset(train_df, is_train=True, batch_size=batch_size)\n",
    "    test_loader  = get_dataset(test_df, is_train=False, batch_size=batch_size)\n",
    "    model, criterion, optimizer = get_model(params)\n",
    "\n",
    "    # Train with modest epochs; early stopping inside fit handles rest\n",
    "    history = model.fit(\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        epochs=60,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        patience=15\n",
    "    )\n",
    "\n",
    "    acc, *_ = get_validation(model, test_loader, device)\n",
    "    accs.append(acc)\n",
    "\n",
    "    print(f\"Fold {i + 1} Accuracy:\", acc)\n",
    "\n",
    "print(f\"LOSOCV Mean Accuracy: {np.mean(accs):.4f} ± {np.std(accs):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3934c02-1f26-4db2-8c1b-6d45ad199e8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "params = {'batch_size': 48, 'cnn_dense': 64, 'cnn_dropout': np.float64(0.5130373328759822), 'cnn_kernel_size_1': 5, 'cnn_kernel_size_2': 5, 'cnn_kernels_1': 16, 'cnn_kernels_2': 16, 'learning_rate': np.float64(0.000462968156587811), 'lstm_dense': 256, 'lstm_hidden_size': 128, 'lstm_layers': 1, 'optimizer': 'adam'}\n",
    "\n",
    "df = pd.read_csv(\"./processed_clustered_adhdata.csv\")\n",
    "\n",
    "frequency_count = len(df['Frequency'].unique())\n",
    "window_count = len(df['Window'].unique())\n",
    "numeric_df = df.drop(['ID', 'Window'], axis=1)\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "# shape: (windows, frequencies, electrodes)\n",
    "full_ndarray = numeric_df.values.reshape((window_count, frequency_count, numeric_df.shape[1]))\n",
    "\n",
    "X = full_ndarray[:, :, 2:]     # drop ID/Class columns\n",
    "y = full_ndarray[:, 0, 0]      # class label is repeated across freq rows\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Add channel dimension (N, 1, freq, electrodes)\n",
    "X_train = X_train[..., np.newaxis]   # (N, freq, electrodes, 1)\n",
    "X_test  = X_test[...,  np.newaxis]\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)  # (N, freq, electrodes, 1)\n",
    "train_ds = EEGDataset(X_train, y_train)\n",
    "test_ds  = EEGDataset(X_test,  y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "unique_samples = list(df['Window'].unique())\n",
    "subject_count = df['ID'].nunique()\n",
    "accs = []\n",
    "variances = []\n",
    "batch_size = params['batch_size']\n",
    "\n",
    "model, criterion, optimizer = get_model(params)\n",
    "\n",
    "# Train with modest epochs; early stopping inside fit handles rest\n",
    "history = model.fit(\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=60,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    patience=15\n",
    ")\n",
    "\n",
    "acc, *_ = get_validation(model, test_loader, device)\n",
    "accs.append(acc)\n",
    "\n",
    "print(f\"Fold {i + 1} Accuracy:\", acc)\n",
    "\n",
    "print(f\"LOSOCV Mean Accuracy: {np.mean(accs):.4f} ± {np.std(accs):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c75e90b-0cac-4fd9-8f54-5d2d380581ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, report, matrix = get_validation(model, test_loader, device)\n",
    "\n",
    "print(\"\\nval Accuracy:\", acc)\n",
    "print(report)\n",
    "print(matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
